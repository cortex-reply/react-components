/*! For license information please see pages-Blog-stories.3cc967d5.iframe.bundle.js.LICENSE.txt */
"use strict";(self.webpackChunkcortex_react_components=self.webpackChunkcortex_react_components||[]).push([[5890],{"./src/pages/Blog.stories.tsx":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{__webpack_require__.r(__webpack_exports__),__webpack_require__.d(__webpack_exports__,{AReallyLongTitle:()=>AReallyLongTitle,Default:()=>Default,LotsOfFormatting:()=>LotsOfFormatting,__namedExportsOrder:()=>__namedExportsOrder,default:()=>Blog_stories});var jsx_runtime=__webpack_require__("./node_modules/.pnpm/next@15.1.3_@babel+core@7.26.0_react-dom@19.0.0_react@19.0.0__react@19.0.0_sass@1.83.0/node_modules/next/dist/compiled/react/jsx-runtime.js"),Header=(__webpack_require__("./node_modules/.pnpm/next@15.1.3_@babel+core@7.26.0_react-dom@19.0.0_react@19.0.0__react@19.0.0_sass@1.83.0/node_modules/next/dist/compiled/react/index.js"),__webpack_require__("./src/components/HeaderFooter/Header.tsx")),PostHero=__webpack_require__("./src/components/Heros/PostHero/index.tsx"),cortex_reply_light=__webpack_require__("./src/images/cortex-reply-light.png"),cortex_reply_dark=__webpack_require__("./src/images/cortex-reply-dark.png"),BlogDetail=__webpack_require__("./src/sections/BlogDetail.tsx");function WebsiteSection({...args}){return(0,jsx_runtime.jsxs)("div",{children:[(0,jsx_runtime.jsx)(Header.Y,{isMenuOpen:!0,logoLight:cortex_reply_light.A,logoDark:cortex_reply_dark.A}),(0,jsx_runtime.jsx)(PostHero.H,{...args.hero}),(0,jsx_runtime.jsx)(BlogDetail.s,{className:"!pb-0",...args.blog})]})}WebsiteSection.__docgenInfo={description:"",methods:[],displayName:"WebsiteSection"};const Blog_stories={title:"Example Pages/Blog",component:WebsiteSection,tags:["autodocs"],parameters:{nextjs:{appDirectory:!0},docs:{description:{component:"Example Blog page."}}}},Default={args:{hero:{type:"postHero",post:{id:"1",title:"Sample Post Title",categories:[{id:"1",title:"Category 1"},{id:"2",title:"Category 2"}],meta:{image:{url:"stock1.jpg"}},populatedAuthors:[{id:"1",name:"Author 1",avatar:{id:"1",url:"/path/to/avatar1.jpg",alt:"Author 1 Avatar"}},{id:"2",name:"Author 2",avatar:{id:"2",url:"/path/to/avatar2.jpg",alt:"Author 2 Avatar"}}],publishedAt:"2023-10-01T12:00:00Z",content:"Sample post content..."}},blog:{edit:!0,categoryList:{title:"Categories",links:[{label:"Category 1",href:1},{label:"Category 2",href:2},{label:"Category 3",href:3}]},page:{id:2,title:"Test Post 2",content:{root:{type:"root",format:"",indent:0,version:1,children:[{type:"paragraph",format:"",indent:0,version:1,children:[{mode:"normal",text:"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus lacinia odio vitae vestibulum vestibulum. Cras vehicula, libero a pharetra dictum, urna lectus porttitor lacus, at dapibus justo quam vel metus. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Sed non velit nec arcu volutpat dignissim in a lorem.",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0},{type:"paragraph",format:"",indent:0,version:1,children:[],direction:null,textStyle:"",textFormat:0},{type:"paragraph",format:"",indent:0,version:1,children:[{mode:"normal",text:"Proin sagittis sem et elit fringilla, nec fringilla eros maximus. Nulla facilisi. Ut sit amet facilisis lectus. Fusce ornare metus at ante tristique, nec elementum eros fermentum. Integer volutpat magna sed justo tincidunt, sit amet aliquam arcu pellentesque. Phasellus imperdiet mi vitae ligula pharetra, a dignissim velit vehicula.",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0},{type:"paragraph",format:"",indent:0,version:1,children:[],direction:null,textStyle:"",textFormat:0},{type:"paragraph",format:"",indent:0,version:1,children:[{mode:"normal",text:"Suspendisse potenti. Donec malesuada arcu at velit laoreet convallis. Sed at eros vel lacus varius varius nec id metus. Praesent faucibus, orci a varius dapibus, lorem libero convallis est, et consequat libero magna sit amet risus. Maecenas tincidunt erat et felis sodales, nec malesuada sem tincidunt. Duis sed nisl euismod, ullamcorper augue at, rutrum felis.",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0},{type:"paragraph",format:"",indent:0,version:1,children:[],direction:null,textStyle:"",textFormat:0},{type:"paragraph",format:"",indent:0,version:1,children:[{mode:"normal",text:"Aenean ut ligula ac libero vehicula luctus. Integer ultricies nisl id mi dictum, eget tincidunt augue interdum. Sed eu malesuada erat. Nam fringilla lectus id dolor gravida lacinia. Aliquam erat volutpat. Vestibulum nec ipsum vitae elit dapibus suscipit vel at ipsum.",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0}],direction:"ltr"}},relatedPosts:[],categories:[{id:1,title:"Test Category 1",slug:"test-category-1",updatedAt:"2025-01-06T20:16:54.416Z",createdAt:"2025-01-06T20:16:54.416Z",_status:"published"}],meta:{title:"Test Post 1",image:null,description:null},publishedAt:"2025-01-06T20:17:25.595Z",authors:[{id:1,name:"Rob",jobRole:null,profilePicture:null,workHistory:[],certifications:[],areasOfExpertise:[],dateOfBirth:null,joinDate:null,role:"admin",sub:null,updatedAt:"2025-01-06T20:16:54.416Z",createdAt:"2025-01-06T20:16:54.416Z",enableAPIKey:null,apiKey:null,email:"rob@sdsdd.com",loginAttempts:0},{id:2,name:"Dave",jobRole:null,profilePicture:null,workHistory:[],certifications:[],areasOfExpertise:[],dateOfBirth:null,joinDate:null,role:"admin",sub:null,updatedAt:"2025-01-06T20:16:54.416Z",createdAt:"2025-01-06T20:16:54.416Z",enableAPIKey:null,apiKey:null,email:"rob@sdsdd.com",loginAttempts:0}],populatedAuthors:[{id:1,name:"Rob Ellison"}],publishedToWebsite:!1,slug:"test-post-2",slugLock:!0,updatedAt:"2025-01-06T20:17:31.465Z",createdAt:"2025-01-06T20:17:27.818Z",_status:"published"}}}},AReallyLongTitle={args:{...Default.args,hero:{...Default.args.hero,post:{...Default.args.hero.post,title:"Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas."}}}},LotsOfFormatting={args:{...Default.args,blog:{edit:!0,categoryList:{title:"Categories",links:[{label:"Category 1",href:1},{label:"Category 2",href:2},{label:"Category 3",href:3}]},page:{id:3,title:"FinOps-enhanced GenAI: Inform, Optimise, Operate, Innovate",content:{root:{type:"root",format:"",indent:0,version:1,children:[{tag:"h4",type:"heading",format:"start",indent:0,version:1,children:[{mode:"normal",text:"The Next Wave of IT Innovation: Generative AI",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"quote",format:"start",indent:0,version:1,children:[{type:"paragraph",format:"start",indent:0,version:1,children:[{mode:"normal",text:"“Generative AI could expand to 10-12% of total information-technology hardware, software, services, advertising, and gaming expenditures by 2032 from less than 1% today, according to our analysis. Training of AI platforms (creating a machine-learning model using large datasets) will be key, driven initially by spending on servers and storage and eventually by cloud-related infrastructure” Bloomberg, 8th March 2024",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0}],direction:"ltr"},{type:"paragraph",format:"start",indent:0,version:1,children:[{mode:"normal",text:"Over the past six months, we have seen an increase in boardroom discussions about AI solutions. This is a clear indication that leadership recognises AI's transformative potential to enhance business operations and deliver significant value. ",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"However, as exciting as these possibilities are, we must not overlook a critical factor: ",type:"text",style:"",detail:0,format:0,version:1},{mode:"normal",text:"cost",type:"text",style:"",detail:0,format:1,version:1},{mode:"normal",text:".",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0},{type:"paragraph",format:"",indent:0,version:1,children:[],direction:"ltr",textStyle:"",textFormat:0},{tag:"h4",type:"heading",format:"",indent:0,version:1,children:[{mode:"normal",text:"Drive cost awareness in generative AI with FinOps",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"paragraph",format:"start",indent:0,version:1,children:[{mode:"normal",text:"From a cost perspective, generative AI tools and applications follow the same principles as every other digital product implemented in the cloud.",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"Organisations will use their existing FinOps processes and tools to:",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0},{tag:"ul",type:"list",start:1,format:"",indent:0,version:1,children:[{type:"listitem",value:1,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Ingest and normalise cost and usage data",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"listitem",value:2,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Allocate and share the cost of cloud services",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"listitem",value:3,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Manage spend anomalies",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"listitem",value:4,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Define a budget for cloud spend and forecast digital product costs",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"}],listType:"bullet",direction:"ltr"},{type:"paragraph",format:"start",indent:0,version:1,children:[{mode:"normal",text:"When approaching generative AI, the main cost that a FinOps team should focus on is the one the organisation will be charged for model inference and customisation.",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{mode:"normal",text:"This expense is caused by the consumption of computing resources every time an LLM is given an input (or prompt) in order to produce an output (or completion).",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"Generative AI models break down text data into units called tokens for processing. The way text data is converted into tokens depends on the tokenizer used. A token can be characters, words, or phrases. Generative AI usually charges by every 1000 tokens of input (prompt) and output (response): i.e.:",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"An application developer makes the following API calls to Amazon Bedrock in the US West (Oregon) Region: a request to Anthropic’s Claude model to summarise an input of 11K tokens of input text to an output of 4K tokens. ",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"Total cost incurred = 11K tokens/1000 x $0.008 + 4K tokens/1000 x $0.024 = $0.088 + $0.096 = ",type:"text",style:"",detail:0,format:0,version:1},{mode:"normal",text:"$0.184",type:"text",style:"",detail:0,format:1,version:1}],direction:"ltr",textStyle:"",textFormat:0},{type:"paragraph",format:"",indent:0,version:1,children:[],direction:"ltr",textStyle:"",textFormat:0},{tag:"h4",type:"heading",format:"",indent:0,version:1,children:[{mode:"normal",text:"Cost-Effective GenAI: Design for Efficiency",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"paragraph",format:"start",indent:0,version:1,children:[{mode:"normal",text:"The cost optimisation techniques supported by FinOps translate perfectly to the realm of generative AI. Just like any cloud-based service, GenAI tools incur ongoing expenses that require careful management. ",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"FinOps tenets like rightsizing resources, leveraging automation for cost control, and negotiating committed-use discounts with cloud providers can effectively be applied to GenAI. However, since inference is a major cost driver for GenAI products, we must architect solutions accurately. This ensures prompts minimise token counts while maintaining desired response accuracy, and uses the appropriate foundational model for maximum value.",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"To illustrate a poorly architected solution's cost impact, consider 200 large text documents (around 10,000 tokens each) containing detailed information on a specific topic. For each document, we want to distil the information into a concise summary and generate additional content based on that summary.",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"Lazy option",type:"text",style:"",detail:0,format:1,version:1},{type:"linebreak",version:1},{mode:"normal",text:"We decide to utilise the Claude 3 Sonnet model from AWS Bedrock, which would perform the task and produce 1000 tokens output",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"Total cost = Claude (0.003 x 10 + 0.015 x 1) = 0.045$ for a single inference x 200 = ",type:"text",style:"",detail:0,format:0,version:1},{mode:"normal",text:"9$ for 200 summaries",type:"text",style:"",detail:0,format:1,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"Well-architected option",type:"text",style:"",detail:0,format:1,version:1},{type:"linebreak",version:1},{mode:"normal",text:"We decide to implement a model chaining pattern, to separate the summarisation and the content creation stages. A simple Mistral 8*7B would create a 500 output tokens per document, feeding into Claude 3 Sonnet, to produce the same 1000 tokens output",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"Total cost = Mistral (0.00045 x 10 + 0.0007 x 0.5) + Claude (0.003 x 0.5 + 0.015 x 1) = 0.021$ for a single inference x 200 = ",type:"text",style:"",detail:0,format:0,version:1},{mode:"normal",text:"4.2$ for 200 summaries",type:"text",style:"",detail:0,format:1,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"By carefully designing the solution (model selection and chaining), we achieved a ",type:"text",style:"",detail:0,format:0,version:1},{mode:"normal",text:"46% cost saving",type:"text",style:"",detail:0,format:1,version:1},{mode:"normal",text:" without compromising accuracy.",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"When building a chaining model for your AI implementation, using the right LLM at each stage is key to keeping costs low. For example, if you have to implement ",type:"text",style:"",detail:0,format:0,version:1},{mode:"normal",text:"pre-scanning",type:"text",style:"",detail:0,format:1,version:1},{mode:"normal",text:" and ",type:"text",style:"",detail:0,format:0,version:1},{mode:"normal",text:"post-scanning",type:"text",style:"",detail:0,format:1,version:1},{mode:"normal",text:" of a user inference, each potentially requires a separate LLM.  ",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0},{type:"paragraph",format:"start",indent:0,version:1,children:[{mode:"normal",text:"A poorly architected chaining model can incur LLM charges that are ",type:"text",style:"",detail:0,format:0,version:1},{mode:"normal",text:"100 times higher",type:"text",style:"",detail:0,format:1,version:1},{mode:"normal",text:" than necessary.",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"Here are a few ideas for a well-architected AI pattern:",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0},{tag:"ul",type:"list",start:1,format:"",indent:0,version:1,children:[{type:"listitem",value:1,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Use smaller, task-specific models for pre-scanning (intent) and post-scanning (response generation). This leverages their strengths and avoids paying for unnecessary capabilities.",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"listitem",value:2,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Hard-code common responses (confirmations, refusals, etc.) to eliminate LLM usage entirely.",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"listitem",value:3,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Pre-compute responses for limited user inputs (e.g. category selections) and store them for retrieval, minimising real-time LLM calls.",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"}],listType:"bullet",direction:"ltr"},{type:"paragraph",format:"start",indent:0,version:1,children:[{type:"linebreak",version:1},{mode:"normal",text:"Let us look at another scenario: ",type:"text",style:"",detail:0,format:1,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"An e-commerce chatbot is designed to handle customer inquiries about product availability and order status. ",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:1},{type:"paragraph",format:"start",indent:0,version:1,children:[{mode:"normal",text:"Poorly Architected Approach",type:"text",style:"",detail:0,format:9,version:1}],direction:"ltr",textStyle:"",textFormat:9},{tag:"ul",type:"list",start:1,format:"",indent:0,version:1,children:[{type:"listitem",value:1,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Single Powerful LLM",type:"text",style:"",detail:0,format:1,version:1}],direction:"ltr"},{type:"listitem",value:2,format:"start",indent:0,version:1,children:[{mode:"normal",text:"The developers use a single, powerful LLM for both pre-scanning and post-scanning ($0.06 per 1,000 tokens). This LLM requires processing 100 tokens per user interaction (including the user's question and the system's response). ",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"listitem",value:3,format:"start",indent:0,version:1,children:[{mode:"normal",text:"High Cost: Every user interaction, even simple ones, requires processing by this expensive LLM. This translates to a cost of $0.06 per 1,000 tokens x 100 tokens/interaction = $0.006 per interaction.",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"}],listType:"bullet",direction:"ltr"},{type:"paragraph",format:"start",indent:0,version:1,children:[{mode:"normal",text:"Cost Breakdown",type:"text",style:"",detail:0,format:1,version:1}],direction:"ltr",textStyle:"",textFormat:1},{tag:"ul",type:"list",start:1,format:"",indent:0,version:1,children:[{type:"listitem",value:1,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Assuming the chatbot handles 10,000 interactions per day, the daily cost would be $0.006/interaction x 10,000 interactions = $60.",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"listitem",value:2,format:"start",indent:0,version:1,children:[{mode:"normal",text:"This translates to a monthly cost of $60/day x 30 days = ",type:"text",style:"",detail:0,format:0,version:1},{mode:"normal",text:"$1800",type:"text",style:"",detail:0,format:1,version:1},{mode:"normal",text:".",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"}],listType:"bullet",direction:"ltr"},{type:"paragraph",format:"start",indent:0,version:1,children:[{mode:"normal",text:"Well-Architected Approach",type:"text",style:"",detail:0,format:9,version:1}],direction:"ltr",textStyle:"",textFormat:9},{tag:"ul",type:"list",start:1,format:"",indent:0,version:1,children:[{type:"listitem",value:1,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Specialised LLMs",type:"text",style:"",detail:0,format:1,version:1}],direction:"ltr"},{type:"listitem",value:2,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Pre-scanning: A smaller LLM, optimised for intent recognition, analyses the user's question. It requires just 20 tokens for processing and costs $0.003 per 1,000 tokens.",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"listitem",value:3,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Post-scanning: Another, even smaller LLM, retrieves product information and order details from the database and generates a concise response, requiring 50 tokens. This LLM costs $0.006 per 1,000 tokens.",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"listitem",value:4,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Hard-coding: The chatbot is programmed with pre-defined responses for common inquiries, eliminating LLM processing for these interactions altogether. Cost is null.",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"listitem",value:5,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Pre-computing: For product categories with a limited number of options, pre-generated responses for availability can be stored. The chatbot retrieves the appropriate response based on user selection, further minimising LLM usage. Cost is also null.",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"}],listType:"bullet",direction:"ltr"},{type:"paragraph",format:"start",indent:0,version:1,children:[{mode:"normal",text:"Cost Breakdown",type:"text",style:"",detail:0,format:1,version:1}],direction:"ltr",textStyle:"",textFormat:1},{tag:"ul",type:"list",start:1,format:"",indent:0,version:1,children:[{type:"listitem",value:1,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Pre-scanning LLM: $.003 per 1,000 tokens x 20 tokens/interaction = $0.00006 per interaction ",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"listitem",value:2,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Post-scanning LLM: $.006 per 1,000 tokens x 50 tokens/interaction = $0.0003 per interaction",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"listitem",value:3,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Hard-coded and pre-computed responses: $0 cost",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"}],listType:"bullet",direction:"ltr"},{type:"paragraph",format:"start",indent:0,version:1,children:[{mode:"normal",text:"Assuming an even split between pre-scanning and post-scanning interactions (5,000 each per day), the total daily cost becomes:",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0},{tag:"ul",type:"list",start:1,format:"",indent:0,version:1,children:[{type:"listitem",value:1,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Pre-scanning cost: $0.00006/interaction x 5,000 interactions = $0.3",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"listitem",value:2,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Post-scanning cost: $0.0003/interaction x 5,000 interactions = $1.5",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"listitem",value:3,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Hard-coded/pre-computed responses: $0 cost",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"}],listType:"bullet",direction:"ltr"},{type:"paragraph",format:"start",indent:0,version:1,children:[{mode:"normal",text:"Combined, the daily cost is $1.8. This translates to a monthly cost of $1.8/day x 30 days = ",type:"text",style:"",detail:0,format:0,version:1},{mode:"normal",text:"$54",type:"text",style:"",detail:0,format:1,version:1},{mode:"normal",text:".",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"By implementing a ",type:"text",style:"",detail:0,format:0,version:1},{mode:"normal",text:"well-architected",type:"text",style:"",detail:0,format:1,version:1},{mode:"normal",text:" design, this example demonstrates a potential ",type:"text",style:"",detail:0,format:0,version:1},{mode:"normal",text:"97% reduction",type:"text",style:"",detail:0,format:1,version:1},{mode:"normal",text:" in monthly costs ($1800 vs $54) by using specialised LLMs, hard-coded responses, and pre-computed responses. This highlights the substantial financial benefits of a well-architected chaining model for your AI chatbot.",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"A further approach to enhancing performance and minimising the total cost of ownership (TCO) for GenAI products is ",type:"text",style:"",detail:0,format:0,version:1},{mode:"normal",text:"Retrieval-Augmented Generation",type:"text",style:"",detail:0,format:1,version:1},{mode:"normal",text:" (RAG). RAG optimises the workload for foundational models by pre-selecting relevant information. Instead of requiring the expensive generative model to process information from scratch, RAG efficiently reduces the volume of text the model needs to handle. ",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"This is achieved by first retrieving pertinent information from a knowledge base or corpus, and then augmenting the generative model with this pre-selected, relevant context only. By avoiding the need to process irrelevant information, RAG leads to fewer tokens being processed by the costly model, subsequently lowering inference costs while maintaining high-quality outputs.",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"However, to implement RAG a number of Cloud services (compute, storage, network, etc) need to be deployed, and this will increase the overall TCO for the implementation, as explored in detail further below.",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0},{type:"paragraph",format:"",indent:0,version:1,children:[],direction:"ltr",textStyle:"",textFormat:0},{tag:"h4",type:"heading",format:"",indent:0,version:1,children:[{mode:"normal",text:"The right model for the right application",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"paragraph",format:"start",indent:0,version:1,children:[{mode:"normal",text:"Various models come with diverse computational needs and functionalities. Opting for a model that aligns well with the project's objectives, without overcomplicating with unnecessary features, can notably reduce overall expenses.",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"The factors that may influence the choice of a Generative AI foundational model for your application are multiple, i.e.:",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0},{tag:"ul",type:"list",start:1,format:"",indent:0,version:1,children:[{type:"listitem",value:1,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Task type",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"listitem",value:2,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Accuracy",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"listitem",value:3,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Performance",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"listitem",value:4,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Supported number of input/output tokens",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"listitem",value:5,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Multi-language support",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"}],listType:"bullet",direction:"ltr"},{type:"paragraph",format:"start",indent:0,version:1,children:[{mode:"normal",text:"Considering such factors is key to ensure the maximisation of business value of the generative AI application because, even within a single family of models, there is a wide range of options available, each with a significantly different cost associated with it.",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"Let’s take the AWS offering as an example below which displays On-demand and batch pricing for Anthropic AI models on AWS Bedrock. ",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0},{type:"paragraph",format:"",indent:0,version:1,children:[],direction:null,textStyle:"",textFormat:0},{type:"table",format:"",indent:0,version:1,children:[{type:"tablerow",format:"",indent:0,version:1,children:[{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:"Model",type:"text",style:"",detail:0,format:1,version:1}],direction:"ltr",textStyle:"",textFormat:0}],direction:"ltr",headerState:3,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:"Price per 1,000 input tokens",type:"text",style:"",detail:0,format:1,version:1}],direction:"ltr",textStyle:"",textFormat:0}],direction:"ltr",headerState:1,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:" Price per 1,000 output tokens",type:"text",style:"",detail:0,format:1,version:1}],direction:"ltr",textStyle:"",textFormat:0}],direction:"ltr",headerState:1,backgroundColor:null}],direction:"ltr"},{type:"tablerow",format:"",indent:0,version:1,children:[{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:"Claude Instant",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0}],direction:"ltr",headerState:2,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:"$0.0008",type:"text",style:"",detail:0,format:0,version:1}],direction:null,textStyle:"",textFormat:0}],direction:null,headerState:0,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:" $0.0024",type:"text",style:"",detail:0,format:0,version:1}],direction:null,textStyle:"",textFormat:0}],direction:null,headerState:0,backgroundColor:null}],direction:null},{type:"tablerow",format:"",indent:0,version:1,children:[{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:"Claude 2.0/2.1 ",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0}],direction:"ltr",headerState:2,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:" $0.008  ",type:"text",style:"",detail:0,format:0,version:1}],direction:null,textStyle:"",textFormat:0}],direction:null,headerState:0,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:" $0.024",type:"text",style:"",detail:0,format:0,version:1}],direction:null,textStyle:"",textFormat:0}],direction:null,headerState:0,backgroundColor:null}],direction:null},{type:"tablerow",format:"",indent:0,version:1,children:[{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:"Claude 3 Opus    ",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0}],direction:"ltr",headerState:2,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:" $0.015 ",type:"text",style:"",detail:0,format:0,version:1}],direction:null,textStyle:"",textFormat:0}],direction:null,headerState:0,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:" $0.075",type:"text",style:"",detail:0,format:0,version:1}],direction:null,textStyle:"",textFormat:0}],direction:null,headerState:0,backgroundColor:null}],direction:null},{type:"tablerow",format:"",indent:0,version:1,children:[{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:"Claude 3 Sonnet ",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0}],direction:"ltr",headerState:2,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:" $0.003",type:"text",style:"",detail:0,format:0,version:1}],direction:null,textStyle:"",textFormat:0}],direction:null,headerState:0,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:" $0.015",type:"text",style:"",detail:0,format:0,version:1}],direction:null,textStyle:"",textFormat:0}],direction:null,headerState:0,backgroundColor:null}],direction:null},{type:"tablerow",format:"",indent:0,version:1,children:[{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:"Claude 3 Haiku  ",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0}],direction:"ltr",headerState:2,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:" $0.00025  ",type:"text",style:"",detail:0,format:0,version:1}],direction:null,textStyle:"",textFormat:0}],direction:null,headerState:0,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:" $0.00125",type:"text",style:"",detail:0,format:0,version:1}],direction:null,textStyle:"",textFormat:0}],direction:null,headerState:0,backgroundColor:null}],direction:null}],colWidths:[199,323,347],direction:null},{type:"paragraph",format:"",indent:0,version:1,children:[{mode:"normal",text:"The price difference between Claude Instant and Opus models is significant. The table below explores the reasons behind this. ",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0},{type:"paragraph",format:"",indent:0,version:1,children:[],direction:null,textStyle:"",textFormat:0},{type:"paragraph",format:"",indent:0,version:1,children:[],direction:null,textStyle:"",textFormat:0},{type:"table",format:"",indent:0,version:1,children:[{type:"tablerow",format:"",indent:0,version:1,children:[{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:"Model",type:"text",style:"",detail:0,format:1,version:1}],direction:"ltr",textStyle:"",textFormat:0}],direction:"ltr",headerState:3,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:"Max Tokens",type:"text",style:"",detail:0,format:1,version:1}],direction:"ltr",textStyle:"",textFormat:1}],direction:"ltr",headerState:1,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:"Languages",type:"text",style:"",detail:0,format:1,version:1}],direction:"ltr",textStyle:"",textFormat:1}],direction:"ltr",headerState:1,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:"Use Cases",type:"text",style:"",detail:0,format:1,version:1}],direction:"ltr",textStyle:"",textFormat:1}],direction:"ltr",headerState:1,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"",indent:0,version:1,children:[],direction:null,textStyle:"",textFormat:0}],direction:"ltr",headerState:1,backgroundColor:null}],direction:"ltr"},{type:"tablerow",format:"",indent:0,version:1,children:[{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:"Instant ",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0}],direction:"ltr",headerState:2,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:"100K",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0}],direction:"ltr",headerState:0,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:"English and multiple other languages",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0}],direction:"ltr",headerState:0,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:"Casual dialogue, text analysis, summarisation, and document comprehension.",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0}],direction:"ltr",headerState:0,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"",indent:0,version:1,children:[],direction:null,textStyle:"",textFormat:0}],direction:"ltr",headerState:0,backgroundColor:null}],direction:"ltr"},{type:"tablerow",format:"",indent:0,version:1,children:[{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:"Opus ",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0}],direction:"ltr",headerState:2,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:"200K",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0}],direction:"ltr",headerState:0,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:"English, Spanish, Japanese, and multiple other languages ",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0}],direction:"ltr",headerState:0,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"center",indent:0,version:1,children:[{mode:"normal",text:"Task automation, interactive coding, research review, brainstorming and hypothesis generation, advanced analysis of charts and graphs, financials and market trends, forecasting",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0}],direction:"ltr",headerState:0,backgroundColor:null},{type:"tablecell",format:"",indent:0,colSpan:1,rowSpan:1,version:1,children:[{type:"paragraph",format:"",indent:0,version:1,children:[],direction:null,textStyle:"",textFormat:0}],direction:"ltr",headerState:0,backgroundColor:null}],direction:"ltr"}],colWidths:[92,110,152,552,552],direction:null},{type:"paragraph",format:"start",indent:0,version:1,children:[{mode:"normal",text:"The pricing data highlights the importance of selecting the appropriate model for your use case. Opting for the wrong model could result in costs that are nearly 20 times higher than necessary, significantly impacting the overall implementation expenses.",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"Larger and more complex models like GPT-3 or PaLM require significantly more computational resources for training and inference, leading to higher costs. Selecting a smaller, more efficient model can reduce costs if the application does not require the full capabilities of a larger model. ",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"For instance, Anthropic Claude 3 Sonnet, with its larger context size of 12K tokens, excels at complex tasks like dialogues and creative content generation but costs $0.003 per 1K tokens on Amazon Bedrock. In contrast, the simpler Amazon Titan Text Express, suitable for summarisation and basic text generation, is nearly four times cheaper at $0.0008 per 1K tokens. ",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"Considering this, if we want to implement a digital platform that aggregates news articles from various sources and delivers curated content to users based on their preferences and interests, the Amazon Titan Text might be the right foundational model of choice to optimise costs.",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"Another example: let us consider the use case of building an AI assistant for customer service. The OpenAI GPT-3 Davinci model, with its impressive language understanding and generation capabilities, might seem like a natural choice. However, at $0.06 per 1,000 input tokens and $0.06 per 1,000 output tokens, it could quickly become cost-prohibitive for high-volume interactions. On the other hand, the more specialised Anthropic Claude Instant, designed for conversational AI, offers a more cost-effective solution at $0.0008 per 1,000 input tokens and $0.0024 per 1,000 output tokens.   ",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"Given the requirement for real-time, interactive responses in customer service scenarios, the Claude Instant model could potentially deliver the necessary performance at a fraction of the cost, making it the more suitable option for this particular implementation.",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0},{type:"paragraph",format:"",indent:0,version:1,children:[],direction:null,textStyle:"",textFormat:0},{tag:"h4",type:"heading",format:"",indent:0,version:1,children:[{mode:"normal",text:"There are more costs to consider",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"paragraph",format:"start",indent:0,version:1,children:[{mode:"normal",text:"Frequently, when integrating generative AI services within an organisation, it is required to provide domain context to a Generative AI foundation model. This need arises in various scenarios where the model must produce outputs tailored to a specific domain or industry.",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"As explained before, a Retrieval-Augmented Generation (RAG) approach can help provide domain context to a generative AI foundation model. RAG is a technique that combines a pre-trained language model (like GPT-3 or BERT) with a retrieval system (like a search engine or knowledge base). The retrieval system is used to fetch relevant documents or passages from a corpus of domain-specific data, which can then be used to augment the context provided to the language model.",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"However, it is important to note that the implementation of such process will need several additional cloud services for each step, i.e.:",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0},{tag:"ul",type:"list",start:1,format:"",indent:0,version:1,children:[{type:"listitem",value:1,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Data storage  ",type:"text",style:"",detail:0,format:1,version:1},{mode:"normal",text:"AWS S3, Azure Storage Account or GCP bucket ",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"listitem",value:2,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Data Cleanup ",type:"text",style:"",detail:0,format:1,version:1},{mode:"normal",text:"AWS Glue, Azure ML studio or Vertex AI",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"listitem",value:3,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Vector embedding ",type:"text",style:"",detail:0,format:1,version:1},{mode:"normal",text:"AWS OpenSearch with k-nn, Azure CosmosDB for PostgreSQL or Vertex AI Vector Search",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"}],listType:"bullet",direction:"ltr"},{type:"paragraph",format:"start",indent:0,version:1,children:[{mode:"normal",text:"To manage the TCO of the AI implementation there are standard optimisation patterns that can be applied to these services:",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0},{tag:"ul",type:"list",start:1,format:"",indent:0,version:1,children:[{type:"listitem",value:1,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Tiered Storage ",type:"text",style:"",detail:0,format:1,version:1},{mode:"normal",text:"Leverage cost-effective storage options like lifecycle management policies in AWS S3, Azure Blob Storage Archive tier in Azure Storage Account, or Coldline storage class in GCP buckets to archive infrequently accessed data.",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"listitem",value:2,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Serverless Data Processing ",type:"text",style:"",detail:0,format:1,version:1},{mode:"normal",text:"Explore serverless data processing services like AWS Glue ETL jobs or Azure Data Factory pipelines to clean and prepare data efficiently, minimising resource usage.",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"listitem",value:3,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Pay-per-use Vector Embedding ",type:"text",style:"",detail:0,format:1,version:1},{mode:"normal",text:"Utilise managed services with pay-per-use pricing models, like Amazon OpenSearch with Elasticsearch Service for vector embedding and k-nearest neighbours search or consider cost-effective alternatives like Faiss for GPU-based similarity search within Azure Cognitive Services.",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"listitem",value:4,format:"start",indent:0,version:1,children:[{mode:"normal",text:"Automated Training Pipelines ",type:"text",style:"",detail:0,format:1,version:1},{mode:"normal",text:"Consider Vertex AI Pipelines in GCP or Azure Machine Learning pipelines to automate and potentially optimise training workflows for the RAG model, potentially reducing training costs. Explore SageMaker Neo for efficient model deployment on AWS or leverage cost-effective containerisation technologies like Docker for deployment across cloud providers.",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"}],listType:"bullet",direction:"ltr"},{type:"paragraph",format:"",indent:0,version:1,children:[],direction:null,textStyle:"",textFormat:0},{tag:"h4",type:"heading",format:"",indent:0,version:1,children:[{mode:"normal",text:"Conclusion",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr"},{type:"paragraph",format:"start",indent:0,version:1,children:[{mode:"normal",text:"As AI workloads continue to grow in complexity and scale, effective FinOps practices become increasingly crucial for organisations to manage their cloud costs and optimise resource utilisation. ",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"By adopting the right AI architectural patterns, implementing cost monitoring and optimisation strategies, organisations can strike the right balance between innovation and fiscal responsibility.",type:"text",style:"",detail:0,format:0,version:1},{type:"linebreak",version:1},{type:"linebreak",version:1},{mode:"normal",text:"Embracing FinOps principles enables organisations to future-proof their AI investments, ensuring sustainable growth and a competitive edge in the rapidly evolving AI landscape.",type:"text",style:"",detail:0,format:0,version:1}],direction:"ltr",textStyle:"",textFormat:0},{type:"paragraph",format:"",indent:0,version:1,children:[],direction:"ltr",textStyle:"",textFormat:0}],direction:"ltr"}},relatedPosts:[],categories:[{id:2,title:"FinOps",parent:null,breadcrumbs:[{id:"677a812ddf2f2500016a05f5",doc:2,url:null,label:"FinOps"}],updatedAt:"2025-01-05T12:55:09.500Z",createdAt:"2025-01-05T12:55:09.480Z"}],meta:{title:"FinOps-enhanced GenAI | Cortex Reply | AI that works for you",image:{id:119,alt:"FinOps-enhanced GenAI: Inform, Optimise, Operate, Innovate",prefix:"media",updatedAt:"2025-04-01T09:06:10.720Z",createdAt:"2025-04-01T09:06:07.529Z",url:"/api/media/file/zZpFFeluQXVexiYXUJ6lu.jpg",thumbnailURL:"/api/media/file/zZpFFeluQXVexiYXUJ6lu-300x200.jpg",filename:"zZpFFeluQXVexiYXUJ6lu.jpg",mimeType:"image/jpeg",filesize:227036,width:2121,height:1414,focalX:50,focalY:50,sizes:{thumbnail:{url:"/api/media/file/zZpFFeluQXVexiYXUJ6lu-300x200.jpg",width:300,height:200,mimeType:"image/jpeg",filesize:6658,filename:"zZpFFeluQXVexiYXUJ6lu-300x200.jpg"},square:{url:"/api/media/file/zZpFFeluQXVexiYXUJ6lu-500x500.jpg",width:500,height:500,mimeType:"image/jpeg",filesize:35848,filename:"zZpFFeluQXVexiYXUJ6lu-500x500.jpg"},small:{url:"/api/media/file/zZpFFeluQXVexiYXUJ6lu-600x400.jpg",width:600,height:400,mimeType:"image/jpeg",filesize:27963,filename:"zZpFFeluQXVexiYXUJ6lu-600x400.jpg"},medium:{url:"/api/media/file/zZpFFeluQXVexiYXUJ6lu-900x600.jpg",width:900,height:600,mimeType:"image/jpeg",filesize:59628,filename:"zZpFFeluQXVexiYXUJ6lu-900x600.jpg"},large:{url:"/api/media/file/zZpFFeluQXVexiYXUJ6lu-1400x933.jpg",width:1400,height:933,mimeType:"image/jpeg",filesize:121948,filename:"zZpFFeluQXVexiYXUJ6lu-1400x933.jpg"},xlarge:{url:"/api/media/file/zZpFFeluQXVexiYXUJ6lu-1920x1280.jpg",width:1920,height:1280,mimeType:"image/jpeg",filesize:195431,filename:"zZpFFeluQXVexiYXUJ6lu-1920x1280.jpg"}}},description:"See how FinOps enhances GenAI by optimising costs, boosting efficiency, and driving innovation with informed financial and operational strategies."},publishedAt:"2025-02-18T16:04:50.489Z",authors:[{id:16,name:"Derek Ho",email:"d.ho@reply.com",jobRole:"SC2",manager:2,about:"Senior AI & Cloud Consultant",profilePicture:12,workHistory:[],certifications:[],areasOfExpertise:[],dateOfBirth:"2020-10-15T12:00:00.000Z",joinDate:"2021-08-09T12:00:00.000Z",linkedIn:"www.linkedin.com/in/derekmhho",role:"user",updatedAt:"2025-03-17T09:43:57.552Z",createdAt:"2025-01-13T10:49:09.359Z",enableAPIKey:null,apiKey:null},{id:12,name:"Ben Num",email:"b.num@reply.com",jobRole:"C2",manager:3,about:null,profilePicture:15,workHistory:[],certifications:[],areasOfExpertise:[],dateOfBirth:"2025-12-29T12:00:00.000Z",joinDate:"2023-09-11T12:00:00.000Z",linkedIn:null,role:"user",updatedAt:"2025-02-12T15:25:13.837Z",createdAt:"2025-01-10T14:07:25.875Z",enableAPIKey:null,apiKey:null}],populatedAuthors:[{id:"16",name:"Derek Ho"},{id:"12",name:"Ben Num"}],slug:"finops-enhanced-genai-inform-optimise-operate-innovate",slugLock:!0,updatedAt:"2025-04-01T10:03:00.931Z",createdAt:"2025-03-31T20:28:04.118Z"}}}},__namedExportsOrder=["Default","AReallyLongTitle","LotsOfFormatting"];Default.parameters={...Default.parameters,docs:{...Default.parameters?.docs,source:{originalSource:"{\n  args: {\n    // ...Default.args,\n    hero: {\n      type: 'postHero',\n      post: {\n        id: '1',\n        title: 'Sample Post Title',\n        categories: [{\n          id: '1',\n          title: 'Category 1'\n        }, {\n          id: '2',\n          title: 'Category 2'\n        }],\n        meta: {\n          image: {\n            url: 'stock1.jpg'\n          }\n        },\n        populatedAuthors: [{\n          id: '1',\n          name: 'Author 1',\n          avatar: {\n            id: '1',\n            url: '/path/to/avatar1.jpg',\n            alt: 'Author 1 Avatar'\n          }\n        }, {\n          id: '2',\n          name: 'Author 2',\n          avatar: {\n            id: '2',\n            url: '/path/to/avatar2.jpg',\n            alt: 'Author 2 Avatar'\n          }\n        }],\n        publishedAt: '2023-10-01T12:00:00Z',\n        content: 'Sample post content...'\n      }\n    },\n    blog: {\n      edit: true,\n      categoryList: {\n        title: 'Categories',\n        links: [{\n          label: 'Category 1',\n          href: 1\n        }, {\n          label: 'Category 2',\n          href: 2\n        }, {\n          label: 'Category 3',\n          href: 3\n        }]\n      },\n      page: {\n        id: 2,\n        title: 'Test Post 2',\n        content: {\n          root: {\n            type: 'root',\n            format: '',\n            indent: 0,\n            version: 1,\n            children: [{\n              type: 'paragraph',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus lacinia odio vitae vestibulum vestibulum. Cras vehicula, libero a pharetra dictum, urna lectus porttitor lacus, at dapibus justo quam vel metus. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Sed non velit nec arcu volutpat dignissim in a lorem.',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 0\n            }, {\n              type: 'paragraph',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [],\n              direction: null,\n              textStyle: '',\n              textFormat: 0\n            }, {\n              type: 'paragraph',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'Proin sagittis sem et elit fringilla, nec fringilla eros maximus. Nulla facilisi. Ut sit amet facilisis lectus. Fusce ornare metus at ante tristique, nec elementum eros fermentum. Integer volutpat magna sed justo tincidunt, sit amet aliquam arcu pellentesque. Phasellus imperdiet mi vitae ligula pharetra, a dignissim velit vehicula.',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 0\n            }, {\n              type: 'paragraph',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [],\n              direction: null,\n              textStyle: '',\n              textFormat: 0\n            }, {\n              type: 'paragraph',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'Suspendisse potenti. Donec malesuada arcu at velit laoreet convallis. Sed at eros vel lacus varius varius nec id metus. Praesent faucibus, orci a varius dapibus, lorem libero convallis est, et consequat libero magna sit amet risus. Maecenas tincidunt erat et felis sodales, nec malesuada sem tincidunt. Duis sed nisl euismod, ullamcorper augue at, rutrum felis.',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 0\n            }, {\n              type: 'paragraph',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [],\n              direction: null,\n              textStyle: '',\n              textFormat: 0\n            }, {\n              type: 'paragraph',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'Aenean ut ligula ac libero vehicula luctus. Integer ultricies nisl id mi dictum, eget tincidunt augue interdum. Sed eu malesuada erat. Nam fringilla lectus id dolor gravida lacinia. Aliquam erat volutpat. Vestibulum nec ipsum vitae elit dapibus suscipit vel at ipsum.',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 0\n            }],\n            direction: 'ltr'\n          }\n        },\n        relatedPosts: [],\n        categories: [{\n          id: 1,\n          title: 'Test Category 1',\n          slug: 'test-category-1',\n          updatedAt: '2025-01-06T20:16:54.416Z',\n          createdAt: '2025-01-06T20:16:54.416Z',\n          _status: 'published'\n        }],\n        meta: {\n          title: 'Test Post 1',\n          image: null,\n          description: null\n        },\n        publishedAt: '2025-01-06T20:17:25.595Z',\n        authors: [{\n          id: 1,\n          name: 'Rob',\n          jobRole: null,\n          profilePicture: null,\n          workHistory: [],\n          certifications: [],\n          areasOfExpertise: [],\n          dateOfBirth: null,\n          joinDate: null,\n          role: 'admin',\n          sub: null,\n          updatedAt: '2025-01-06T20:16:54.416Z',\n          createdAt: '2025-01-06T20:16:54.416Z',\n          enableAPIKey: null,\n          apiKey: null,\n          email: 'rob@sdsdd.com',\n          loginAttempts: 0\n        }, {\n          id: 2,\n          name: 'Dave',\n          jobRole: null,\n          profilePicture: null,\n          workHistory: [],\n          certifications: [],\n          areasOfExpertise: [],\n          dateOfBirth: null,\n          joinDate: null,\n          role: 'admin',\n          sub: null,\n          updatedAt: '2025-01-06T20:16:54.416Z',\n          createdAt: '2025-01-06T20:16:54.416Z',\n          enableAPIKey: null,\n          apiKey: null,\n          email: 'rob@sdsdd.com',\n          loginAttempts: 0\n        }],\n        populatedAuthors: [{\n          id: 1,\n          name: 'Rob Ellison'\n        }],\n        publishedToWebsite: false,\n        slug: 'test-post-2',\n        slugLock: true,\n        updatedAt: '2025-01-06T20:17:31.465Z',\n        createdAt: '2025-01-06T20:17:27.818Z',\n        _status: 'published'\n      }\n    }\n  }\n}",...Default.parameters?.docs?.source}}},AReallyLongTitle.parameters={...AReallyLongTitle.parameters,docs:{...AReallyLongTitle.parameters?.docs,source:{originalSource:"{\n  args: {\n    ...Default.args,\n    hero: {\n      ...Default.args.hero,\n      post: {\n        ...Default.args.hero.post,\n        title: 'Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas.'\n      }\n    }\n  }\n}",...AReallyLongTitle.parameters?.docs?.source}}},LotsOfFormatting.parameters={...LotsOfFormatting.parameters,docs:{...LotsOfFormatting.parameters?.docs,source:{originalSource:"{\n  args: {\n    ...Default.args,\n    blog: {\n      edit: true,\n      categoryList: {\n        title: 'Categories',\n        links: [{\n          label: 'Category 1',\n          href: 1\n        }, {\n          label: 'Category 2',\n          href: 2\n        }, {\n          label: 'Category 3',\n          href: 3\n        }]\n      },\n      page: {\n        id: 3,\n        title: 'FinOps-enhanced GenAI: Inform, Optimise, Operate, Innovate',\n        content: {\n          root: {\n            type: 'root',\n            format: '',\n            indent: 0,\n            version: 1,\n            children: [{\n              tag: 'h4',\n              type: 'heading',\n              format: 'start',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'The Next Wave of IT Innovation: Generative AI',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr'\n            }, {\n              type: 'quote',\n              format: 'start',\n              indent: 0,\n              version: 1,\n              children: [{\n                type: 'paragraph',\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: '“Generative AI could expand to 10-12% of total information-technology hardware, software, services, advertising, and gaming expenditures by 2032 from less than 1% today, according to our analysis. Training of AI platforms (creating a machine-learning model using large datasets) will be key, driven initially by spending on servers and storage and eventually by cloud-related infrastructure” Bloomberg, 8th March 2024',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr',\n                textStyle: '',\n                textFormat: 0\n              }],\n              direction: 'ltr'\n            }, {\n              type: 'paragraph',\n              format: 'start',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: \"Over the past six months, we have seen an increase in boardroom discussions about AI solutions. This is a clear indication that leadership recognises AI's transformative potential to enhance business operations and deliver significant value. \",\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'However, as exciting as these possibilities are, we must not overlook a critical factor: ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'cost',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 1,\n                version: 1\n              }, {\n                mode: 'normal',\n                text: '.',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 0\n            }, {\n              type: 'paragraph',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 0\n            }, {\n              tag: 'h4',\n              type: 'heading',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'Drive cost awareness in generative AI with FinOps',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr'\n            }, {\n              type: 'paragraph',\n              format: 'start',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'From a cost perspective, generative AI tools and applications follow the same principles as every other digital product implemented in the cloud.',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'Organisations will use their existing FinOps processes and tools to:',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 0\n            }, {\n              tag: 'ul',\n              type: 'list',\n              start: 1,\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [{\n                type: 'listitem',\n                value: 1,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Ingest and normalise cost and usage data',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 2,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Allocate and share the cost of cloud services',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 3,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Manage spend anomalies',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 4,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Define a budget for cloud spend and forecast digital product costs',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }],\n              listType: 'bullet',\n              direction: 'ltr'\n            }, {\n              type: 'paragraph',\n              format: 'start',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'When approaching generative AI, the main cost that a FinOps team should focus on is the one the organisation will be charged for model inference and customisation.',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'This expense is caused by the consumption of computing resources every time an LLM is given an input (or prompt) in order to produce an output (or completion).',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'Generative AI models break down text data into units called tokens for processing. The way text data is converted into tokens depends on the tokenizer used. A token can be characters, words, or phrases. Generative AI usually charges by every 1000 tokens of input (prompt) and output (response): i.e.:',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'An application developer makes the following API calls to Amazon Bedrock in the US West (Oregon) Region: a request to Anthropic’s Claude model to summarise an input of 11K tokens of input text to an output of 4K tokens. ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'Total cost incurred = 11K tokens/1000 x $0.008 + 4K tokens/1000 x $0.024 = $0.088 + $0.096 = ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                mode: 'normal',\n                text: '$0.184',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 1,\n                version: 1\n              }],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 0\n            }, {\n              type: 'paragraph',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 0\n            }, {\n              tag: 'h4',\n              type: 'heading',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'Cost-Effective GenAI: Design for Efficiency',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr'\n            }, {\n              type: 'paragraph',\n              format: 'start',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'The cost optimisation techniques supported by FinOps translate perfectly to the realm of generative AI. Just like any cloud-based service, GenAI tools incur ongoing expenses that require careful management. ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'FinOps tenets like rightsizing resources, leveraging automation for cost control, and negotiating committed-use discounts with cloud providers can effectively be applied to GenAI. However, since inference is a major cost driver for GenAI products, we must architect solutions accurately. This ensures prompts minimise token counts while maintaining desired response accuracy, and uses the appropriate foundational model for maximum value.',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: \"To illustrate a poorly architected solution's cost impact, consider 200 large text documents (around 10,000 tokens each) containing detailed information on a specific topic. For each document, we want to distil the information into a concise summary and generate additional content based on that summary.\",\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'Lazy option',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 1,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'We decide to utilise the Claude 3 Sonnet model from AWS Bedrock, which would perform the task and produce 1000 tokens output',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'Total cost = Claude (0.003 x 10 + 0.015 x 1) = 0.045$ for a single inference x 200 = ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                mode: 'normal',\n                text: '9$ for 200 summaries',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 1,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'Well-architected option',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 1,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'We decide to implement a model chaining pattern, to separate the summarisation and the content creation stages. A simple Mistral 8*7B would create a 500 output tokens per document, feeding into Claude 3 Sonnet, to produce the same 1000 tokens output',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'Total cost = Mistral (0.00045 x 10 + 0.0007 x 0.5) + Claude (0.003 x 0.5 + 0.015 x 1) = 0.021$ for a single inference x 200 = ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                mode: 'normal',\n                text: '4.2$ for 200 summaries',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 1,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'By carefully designing the solution (model selection and chaining), we achieved a ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                mode: 'normal',\n                text: '46% cost saving',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 1,\n                version: 1\n              }, {\n                mode: 'normal',\n                text: ' without compromising accuracy.',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'When building a chaining model for your AI implementation, using the right LLM at each stage is key to keeping costs low. For example, if you have to implement ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'pre-scanning',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 1,\n                version: 1\n              }, {\n                mode: 'normal',\n                text: ' and ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'post-scanning',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 1,\n                version: 1\n              }, {\n                mode: 'normal',\n                text: ' of a user inference, each potentially requires a separate LLM.  ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 0\n            }, {\n              type: 'paragraph',\n              format: 'start',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'A poorly architected chaining model can incur LLM charges that are ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                mode: 'normal',\n                text: '100 times higher',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 1,\n                version: 1\n              }, {\n                mode: 'normal',\n                text: ' than necessary.',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'Here are a few ideas for a well-architected AI pattern:',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 0\n            }, {\n              tag: 'ul',\n              type: 'list',\n              start: 1,\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [{\n                type: 'listitem',\n                value: 1,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Use smaller, task-specific models for pre-scanning (intent) and post-scanning (response generation). This leverages their strengths and avoids paying for unnecessary capabilities.',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 2,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Hard-code common responses (confirmations, refusals, etc.) to eliminate LLM usage entirely.',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 3,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Pre-compute responses for limited user inputs (e.g. category selections) and store them for retrieval, minimising real-time LLM calls.',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }],\n              listType: 'bullet',\n              direction: 'ltr'\n            }, {\n              type: 'paragraph',\n              format: 'start',\n              indent: 0,\n              version: 1,\n              children: [{\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'Let us look at another scenario: ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 1,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'An e-commerce chatbot is designed to handle customer inquiries about product availability and order status. ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 1\n            }, {\n              type: 'paragraph',\n              format: 'start',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'Poorly Architected Approach',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 9,\n                version: 1\n              }],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 9\n            }, {\n              tag: 'ul',\n              type: 'list',\n              start: 1,\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [{\n                type: 'listitem',\n                value: 1,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Single Powerful LLM',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 1,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 2,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: \"The developers use a single, powerful LLM for both pre-scanning and post-scanning ($0.06 per 1,000 tokens). This LLM requires processing 100 tokens per user interaction (including the user's question and the system's response). \",\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 3,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'High Cost: Every user interaction, even simple ones, requires processing by this expensive LLM. This translates to a cost of $0.06 per 1,000 tokens x 100 tokens/interaction = $0.006 per interaction.',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }],\n              listType: 'bullet',\n              direction: 'ltr'\n            }, {\n              type: 'paragraph',\n              format: 'start',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'Cost Breakdown',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 1,\n                version: 1\n              }],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 1\n            }, {\n              tag: 'ul',\n              type: 'list',\n              start: 1,\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [{\n                type: 'listitem',\n                value: 1,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Assuming the chatbot handles 10,000 interactions per day, the daily cost would be $0.006/interaction x 10,000 interactions = $60.',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 2,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'This translates to a monthly cost of $60/day x 30 days = ',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }, {\n                  mode: 'normal',\n                  text: '$1800',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 1,\n                  version: 1\n                }, {\n                  mode: 'normal',\n                  text: '.',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }],\n              listType: 'bullet',\n              direction: 'ltr'\n            }, {\n              type: 'paragraph',\n              format: 'start',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'Well-Architected Approach',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 9,\n                version: 1\n              }],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 9\n            }, {\n              tag: 'ul',\n              type: 'list',\n              start: 1,\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [{\n                type: 'listitem',\n                value: 1,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Specialised LLMs',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 1,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 2,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: \"Pre-scanning: A smaller LLM, optimised for intent recognition, analyses the user's question. It requires just 20 tokens for processing and costs $0.003 per 1,000 tokens.\",\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 3,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Post-scanning: Another, even smaller LLM, retrieves product information and order details from the database and generates a concise response, requiring 50 tokens. This LLM costs $0.006 per 1,000 tokens.',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 4,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Hard-coding: The chatbot is programmed with pre-defined responses for common inquiries, eliminating LLM processing for these interactions altogether. Cost is null.',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 5,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Pre-computing: For product categories with a limited number of options, pre-generated responses for availability can be stored. The chatbot retrieves the appropriate response based on user selection, further minimising LLM usage. Cost is also null.',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }],\n              listType: 'bullet',\n              direction: 'ltr'\n            }, {\n              type: 'paragraph',\n              format: 'start',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'Cost Breakdown',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 1,\n                version: 1\n              }],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 1\n            }, {\n              tag: 'ul',\n              type: 'list',\n              start: 1,\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [{\n                type: 'listitem',\n                value: 1,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Pre-scanning LLM: $.003 per 1,000 tokens x 20 tokens/interaction = $0.00006 per interaction ',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 2,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Post-scanning LLM: $.006 per 1,000 tokens x 50 tokens/interaction = $0.0003 per interaction',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 3,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Hard-coded and pre-computed responses: $0 cost',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }],\n              listType: 'bullet',\n              direction: 'ltr'\n            }, {\n              type: 'paragraph',\n              format: 'start',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'Assuming an even split between pre-scanning and post-scanning interactions (5,000 each per day), the total daily cost becomes:',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 0\n            }, {\n              tag: 'ul',\n              type: 'list',\n              start: 1,\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [{\n                type: 'listitem',\n                value: 1,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Pre-scanning cost: $0.00006/interaction x 5,000 interactions = $0.3',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 2,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Post-scanning cost: $0.0003/interaction x 5,000 interactions = $1.5',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 3,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Hard-coded/pre-computed responses: $0 cost',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }],\n              listType: 'bullet',\n              direction: 'ltr'\n            }, {\n              type: 'paragraph',\n              format: 'start',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'Combined, the daily cost is $1.8. This translates to a monthly cost of $1.8/day x 30 days = ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                mode: 'normal',\n                text: '$54',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 1,\n                version: 1\n              }, {\n                mode: 'normal',\n                text: '.',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'By implementing a ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'well-architected',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 1,\n                version: 1\n              }, {\n                mode: 'normal',\n                text: ' design, this example demonstrates a potential ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                mode: 'normal',\n                text: '97% reduction',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 1,\n                version: 1\n              }, {\n                mode: 'normal',\n                text: ' in monthly costs ($1800 vs $54) by using specialised LLMs, hard-coded responses, and pre-computed responses. This highlights the substantial financial benefits of a well-architected chaining model for your AI chatbot.',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'A further approach to enhancing performance and minimising the total cost of ownership (TCO) for GenAI products is ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'Retrieval-Augmented Generation',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 1,\n                version: 1\n              }, {\n                mode: 'normal',\n                text: ' (RAG). RAG optimises the workload for foundational models by pre-selecting relevant information. Instead of requiring the expensive generative model to process information from scratch, RAG efficiently reduces the volume of text the model needs to handle. ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'This is achieved by first retrieving pertinent information from a knowledge base or corpus, and then augmenting the generative model with this pre-selected, relevant context only. By avoiding the need to process irrelevant information, RAG leads to fewer tokens being processed by the costly model, subsequently lowering inference costs while maintaining high-quality outputs.',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'However, to implement RAG a number of Cloud services (compute, storage, network, etc) need to be deployed, and this will increase the overall TCO for the implementation, as explored in detail further below.',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 0\n            }, {\n              type: 'paragraph',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 0\n            }, {\n              tag: 'h4',\n              type: 'heading',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'The right model for the right application',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr'\n            }, {\n              type: 'paragraph',\n              format: 'start',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: \"Various models come with diverse computational needs and functionalities. Opting for a model that aligns well with the project's objectives, without overcomplicating with unnecessary features, can notably reduce overall expenses.\",\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'The factors that may influence the choice of a Generative AI foundational model for your application are multiple, i.e.:',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 0\n            }, {\n              tag: 'ul',\n              type: 'list',\n              start: 1,\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [{\n                type: 'listitem',\n                value: 1,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Task type',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 2,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Accuracy',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 3,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Performance',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 4,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Supported number of input/output tokens',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 5,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Multi-language support',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }],\n              listType: 'bullet',\n              direction: 'ltr'\n            }, {\n              type: 'paragraph',\n              format: 'start',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'Considering such factors is key to ensure the maximisation of business value of the generative AI application because, even within a single family of models, there is a wide range of options available, each with a significantly different cost associated with it.',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'Let’s take the AWS offering as an example below which displays On-demand and batch pricing for Anthropic AI models on AWS Bedrock. ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 0\n            }, {\n              type: 'paragraph',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [],\n              direction: null,\n              textStyle: '',\n              textFormat: 0\n            }, {\n              type: 'table',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [{\n                type: 'tablerow',\n                format: '',\n                indent: 0,\n                version: 1,\n                children: [{\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: 'Model',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 1,\n                      version: 1\n                    }],\n                    direction: 'ltr',\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: 'ltr',\n                  headerState: 3,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: 'Price per 1,000 input tokens',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 1,\n                      version: 1\n                    }],\n                    direction: 'ltr',\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: 'ltr',\n                  headerState: 1,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: ' Price per 1,000 output tokens',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 1,\n                      version: 1\n                    }],\n                    direction: 'ltr',\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: 'ltr',\n                  headerState: 1,\n                  backgroundColor: null\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'tablerow',\n                format: '',\n                indent: 0,\n                version: 1,\n                children: [{\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: 'Claude Instant',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 0,\n                      version: 1\n                    }],\n                    direction: 'ltr',\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: 'ltr',\n                  headerState: 2,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: '$0.0008',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 0,\n                      version: 1\n                    }],\n                    direction: null,\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: null,\n                  headerState: 0,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: ' $0.0024',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 0,\n                      version: 1\n                    }],\n                    direction: null,\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: null,\n                  headerState: 0,\n                  backgroundColor: null\n                }],\n                direction: null\n              }, {\n                type: 'tablerow',\n                format: '',\n                indent: 0,\n                version: 1,\n                children: [{\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: 'Claude 2.0/2.1 ',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 0,\n                      version: 1\n                    }],\n                    direction: 'ltr',\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: 'ltr',\n                  headerState: 2,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: ' $0.008  ',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 0,\n                      version: 1\n                    }],\n                    direction: null,\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: null,\n                  headerState: 0,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: ' $0.024',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 0,\n                      version: 1\n                    }],\n                    direction: null,\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: null,\n                  headerState: 0,\n                  backgroundColor: null\n                }],\n                direction: null\n              }, {\n                type: 'tablerow',\n                format: '',\n                indent: 0,\n                version: 1,\n                children: [{\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: 'Claude 3 Opus    ',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 0,\n                      version: 1\n                    }],\n                    direction: 'ltr',\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: 'ltr',\n                  headerState: 2,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: ' $0.015 ',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 0,\n                      version: 1\n                    }],\n                    direction: null,\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: null,\n                  headerState: 0,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: ' $0.075',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 0,\n                      version: 1\n                    }],\n                    direction: null,\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: null,\n                  headerState: 0,\n                  backgroundColor: null\n                }],\n                direction: null\n              }, {\n                type: 'tablerow',\n                format: '',\n                indent: 0,\n                version: 1,\n                children: [{\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: 'Claude 3 Sonnet ',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 0,\n                      version: 1\n                    }],\n                    direction: 'ltr',\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: 'ltr',\n                  headerState: 2,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: ' $0.003',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 0,\n                      version: 1\n                    }],\n                    direction: null,\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: null,\n                  headerState: 0,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: ' $0.015',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 0,\n                      version: 1\n                    }],\n                    direction: null,\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: null,\n                  headerState: 0,\n                  backgroundColor: null\n                }],\n                direction: null\n              }, {\n                type: 'tablerow',\n                format: '',\n                indent: 0,\n                version: 1,\n                children: [{\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: 'Claude 3 Haiku  ',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 0,\n                      version: 1\n                    }],\n                    direction: 'ltr',\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: 'ltr',\n                  headerState: 2,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: ' $0.00025  ',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 0,\n                      version: 1\n                    }],\n                    direction: null,\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: null,\n                  headerState: 0,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: ' $0.00125',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 0,\n                      version: 1\n                    }],\n                    direction: null,\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: null,\n                  headerState: 0,\n                  backgroundColor: null\n                }],\n                direction: null\n              }],\n              colWidths: [199, 323, 347],\n              direction: null\n            }, {\n              type: 'paragraph',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'The price difference between Claude Instant and Opus models is significant. The table below explores the reasons behind this. ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 0\n            }, {\n              type: 'paragraph',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [],\n              direction: null,\n              textStyle: '',\n              textFormat: 0\n            }, {\n              type: 'paragraph',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [],\n              direction: null,\n              textStyle: '',\n              textFormat: 0\n            }, {\n              type: 'table',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [{\n                type: 'tablerow',\n                format: '',\n                indent: 0,\n                version: 1,\n                children: [{\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: 'Model',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 1,\n                      version: 1\n                    }],\n                    direction: 'ltr',\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: 'ltr',\n                  headerState: 3,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: 'Max Tokens',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 1,\n                      version: 1\n                    }],\n                    direction: 'ltr',\n                    textStyle: '',\n                    textFormat: 1\n                  }],\n                  direction: 'ltr',\n                  headerState: 1,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: 'Languages',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 1,\n                      version: 1\n                    }],\n                    direction: 'ltr',\n                    textStyle: '',\n                    textFormat: 1\n                  }],\n                  direction: 'ltr',\n                  headerState: 1,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: 'Use Cases',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 1,\n                      version: 1\n                    }],\n                    direction: 'ltr',\n                    textStyle: '',\n                    textFormat: 1\n                  }],\n                  direction: 'ltr',\n                  headerState: 1,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: '',\n                    indent: 0,\n                    version: 1,\n                    children: [],\n                    direction: null,\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: 'ltr',\n                  headerState: 1,\n                  backgroundColor: null\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'tablerow',\n                format: '',\n                indent: 0,\n                version: 1,\n                children: [{\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: 'Instant ',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 0,\n                      version: 1\n                    }],\n                    direction: 'ltr',\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: 'ltr',\n                  headerState: 2,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: '100K',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 0,\n                      version: 1\n                    }],\n                    direction: 'ltr',\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: 'ltr',\n                  headerState: 0,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: 'English and multiple other languages',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 0,\n                      version: 1\n                    }],\n                    direction: 'ltr',\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: 'ltr',\n                  headerState: 0,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: 'Casual dialogue, text analysis, summarisation, and document comprehension.',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 0,\n                      version: 1\n                    }],\n                    direction: 'ltr',\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: 'ltr',\n                  headerState: 0,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: '',\n                    indent: 0,\n                    version: 1,\n                    children: [],\n                    direction: null,\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: 'ltr',\n                  headerState: 0,\n                  backgroundColor: null\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'tablerow',\n                format: '',\n                indent: 0,\n                version: 1,\n                children: [{\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: 'Opus ',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 0,\n                      version: 1\n                    }],\n                    direction: 'ltr',\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: 'ltr',\n                  headerState: 2,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: '200K',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 0,\n                      version: 1\n                    }],\n                    direction: 'ltr',\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: 'ltr',\n                  headerState: 0,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: 'English, Spanish, Japanese, and multiple other languages ',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 0,\n                      version: 1\n                    }],\n                    direction: 'ltr',\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: 'ltr',\n                  headerState: 0,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: 'center',\n                    indent: 0,\n                    version: 1,\n                    children: [{\n                      mode: 'normal',\n                      text: 'Task automation, interactive coding, research review, brainstorming and hypothesis generation, advanced analysis of charts and graphs, financials and market trends, forecasting',\n                      type: 'text',\n                      style: '',\n                      detail: 0,\n                      format: 0,\n                      version: 1\n                    }],\n                    direction: 'ltr',\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: 'ltr',\n                  headerState: 0,\n                  backgroundColor: null\n                }, {\n                  type: 'tablecell',\n                  format: '',\n                  indent: 0,\n                  colSpan: 1,\n                  rowSpan: 1,\n                  version: 1,\n                  children: [{\n                    type: 'paragraph',\n                    format: '',\n                    indent: 0,\n                    version: 1,\n                    children: [],\n                    direction: null,\n                    textStyle: '',\n                    textFormat: 0\n                  }],\n                  direction: 'ltr',\n                  headerState: 0,\n                  backgroundColor: null\n                }],\n                direction: 'ltr'\n              }],\n              colWidths: [92, 110, 152, 552, 552],\n              direction: null\n            }, {\n              type: 'paragraph',\n              format: 'start',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'The pricing data highlights the importance of selecting the appropriate model for your use case. Opting for the wrong model could result in costs that are nearly 20 times higher than necessary, significantly impacting the overall implementation expenses.',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'Larger and more complex models like GPT-3 or PaLM require significantly more computational resources for training and inference, leading to higher costs. Selecting a smaller, more efficient model can reduce costs if the application does not require the full capabilities of a larger model. ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'For instance, Anthropic Claude 3 Sonnet, with its larger context size of 12K tokens, excels at complex tasks like dialogues and creative content generation but costs $0.003 per 1K tokens on Amazon Bedrock. In contrast, the simpler Amazon Titan Text Express, suitable for summarisation and basic text generation, is nearly four times cheaper at $0.0008 per 1K tokens. ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'Considering this, if we want to implement a digital platform that aggregates news articles from various sources and delivers curated content to users based on their preferences and interests, the Amazon Titan Text might be the right foundational model of choice to optimise costs.',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'Another example: let us consider the use case of building an AI assistant for customer service. The OpenAI GPT-3 Davinci model, with its impressive language understanding and generation capabilities, might seem like a natural choice. However, at $0.06 per 1,000 input tokens and $0.06 per 1,000 output tokens, it could quickly become cost-prohibitive for high-volume interactions. On the other hand, the more specialised Anthropic Claude Instant, designed for conversational AI, offers a more cost-effective solution at $0.0008 per 1,000 input tokens and $0.0024 per 1,000 output tokens.   ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'Given the requirement for real-time, interactive responses in customer service scenarios, the Claude Instant model could potentially deliver the necessary performance at a fraction of the cost, making it the more suitable option for this particular implementation.',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 0\n            }, {\n              type: 'paragraph',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [],\n              direction: null,\n              textStyle: '',\n              textFormat: 0\n            }, {\n              tag: 'h4',\n              type: 'heading',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'There are more costs to consider',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr'\n            }, {\n              type: 'paragraph',\n              format: 'start',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'Frequently, when integrating generative AI services within an organisation, it is required to provide domain context to a Generative AI foundation model. This need arises in various scenarios where the model must produce outputs tailored to a specific domain or industry.',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'As explained before, a Retrieval-Augmented Generation (RAG) approach can help provide domain context to a generative AI foundation model. RAG is a technique that combines a pre-trained language model (like GPT-3 or BERT) with a retrieval system (like a search engine or knowledge base). The retrieval system is used to fetch relevant documents or passages from a corpus of domain-specific data, which can then be used to augment the context provided to the language model.',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'However, it is important to note that the implementation of such process will need several additional cloud services for each step, i.e.:',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 0\n            }, {\n              tag: 'ul',\n              type: 'list',\n              start: 1,\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [{\n                type: 'listitem',\n                value: 1,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Data storage  ',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 1,\n                  version: 1\n                }, {\n                  mode: 'normal',\n                  text: 'AWS S3, Azure Storage Account or GCP bucket ',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 2,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Data Cleanup ',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 1,\n                  version: 1\n                }, {\n                  mode: 'normal',\n                  text: 'AWS Glue, Azure ML studio or Vertex AI',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 3,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Vector embedding ',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 1,\n                  version: 1\n                }, {\n                  mode: 'normal',\n                  text: 'AWS OpenSearch with k-nn, Azure CosmosDB for PostgreSQL or Vertex AI Vector Search',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }],\n              listType: 'bullet',\n              direction: 'ltr'\n            }, {\n              type: 'paragraph',\n              format: 'start',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'To manage the TCO of the AI implementation there are standard optimisation patterns that can be applied to these services:',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 0\n            }, {\n              tag: 'ul',\n              type: 'list',\n              start: 1,\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [{\n                type: 'listitem',\n                value: 1,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Tiered Storage ',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 1,\n                  version: 1\n                }, {\n                  mode: 'normal',\n                  text: 'Leverage cost-effective storage options like lifecycle management policies in AWS S3, Azure Blob Storage Archive tier in Azure Storage Account, or Coldline storage class in GCP buckets to archive infrequently accessed data.',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 2,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Serverless Data Processing ',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 1,\n                  version: 1\n                }, {\n                  mode: 'normal',\n                  text: 'Explore serverless data processing services like AWS Glue ETL jobs or Azure Data Factory pipelines to clean and prepare data efficiently, minimising resource usage.',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 3,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Pay-per-use Vector Embedding ',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 1,\n                  version: 1\n                }, {\n                  mode: 'normal',\n                  text: 'Utilise managed services with pay-per-use pricing models, like Amazon OpenSearch with Elasticsearch Service for vector embedding and k-nearest neighbours search or consider cost-effective alternatives like Faiss for GPU-based similarity search within Azure Cognitive Services.',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }, {\n                type: 'listitem',\n                value: 4,\n                format: 'start',\n                indent: 0,\n                version: 1,\n                children: [{\n                  mode: 'normal',\n                  text: 'Automated Training Pipelines ',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 1,\n                  version: 1\n                }, {\n                  mode: 'normal',\n                  text: 'Consider Vertex AI Pipelines in GCP or Azure Machine Learning pipelines to automate and potentially optimise training workflows for the RAG model, potentially reducing training costs. Explore SageMaker Neo for efficient model deployment on AWS or leverage cost-effective containerisation technologies like Docker for deployment across cloud providers.',\n                  type: 'text',\n                  style: '',\n                  detail: 0,\n                  format: 0,\n                  version: 1\n                }],\n                direction: 'ltr'\n              }],\n              listType: 'bullet',\n              direction: 'ltr'\n            }, {\n              type: 'paragraph',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [],\n              direction: null,\n              textStyle: '',\n              textFormat: 0\n            }, {\n              tag: 'h4',\n              type: 'heading',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'Conclusion',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr'\n            }, {\n              type: 'paragraph',\n              format: 'start',\n              indent: 0,\n              version: 1,\n              children: [{\n                mode: 'normal',\n                text: 'As AI workloads continue to grow in complexity and scale, effective FinOps practices become increasingly crucial for organisations to manage their cloud costs and optimise resource utilisation. ',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'By adopting the right AI architectural patterns, implementing cost monitoring and optimisation strategies, organisations can strike the right balance between innovation and fiscal responsibility.',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                type: 'linebreak',\n                version: 1\n              }, {\n                mode: 'normal',\n                text: 'Embracing FinOps principles enables organisations to future-proof their AI investments, ensuring sustainable growth and a competitive edge in the rapidly evolving AI landscape.',\n                type: 'text',\n                style: '',\n                detail: 0,\n                format: 0,\n                version: 1\n              }],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 0\n            }, {\n              type: 'paragraph',\n              format: '',\n              indent: 0,\n              version: 1,\n              children: [],\n              direction: 'ltr',\n              textStyle: '',\n              textFormat: 0\n            }],\n            direction: 'ltr'\n          }\n        },\n        relatedPosts: [],\n        categories: [{\n          id: 2,\n          title: 'FinOps',\n          parent: null,\n          breadcrumbs: [{\n            id: '677a812ddf2f2500016a05f5',\n            doc: 2,\n            url: null,\n            label: 'FinOps'\n          }],\n          updatedAt: '2025-01-05T12:55:09.500Z',\n          createdAt: '2025-01-05T12:55:09.480Z'\n        }],\n        meta: {\n          title: 'FinOps-enhanced GenAI | Cortex Reply | AI that works for you',\n          image: {\n            id: 119,\n            alt: 'FinOps-enhanced GenAI: Inform, Optimise, Operate, Innovate',\n            prefix: 'media',\n            updatedAt: '2025-04-01T09:06:10.720Z',\n            createdAt: '2025-04-01T09:06:07.529Z',\n            url: '/api/media/file/zZpFFeluQXVexiYXUJ6lu.jpg',\n            thumbnailURL: '/api/media/file/zZpFFeluQXVexiYXUJ6lu-300x200.jpg',\n            filename: 'zZpFFeluQXVexiYXUJ6lu.jpg',\n            mimeType: 'image/jpeg',\n            filesize: 227036,\n            width: 2121,\n            height: 1414,\n            focalX: 50,\n            focalY: 50,\n            sizes: {\n              thumbnail: {\n                url: '/api/media/file/zZpFFeluQXVexiYXUJ6lu-300x200.jpg',\n                width: 300,\n                height: 200,\n                mimeType: 'image/jpeg',\n                filesize: 6658,\n                filename: 'zZpFFeluQXVexiYXUJ6lu-300x200.jpg'\n              },\n              square: {\n                url: '/api/media/file/zZpFFeluQXVexiYXUJ6lu-500x500.jpg',\n                width: 500,\n                height: 500,\n                mimeType: 'image/jpeg',\n                filesize: 35848,\n                filename: 'zZpFFeluQXVexiYXUJ6lu-500x500.jpg'\n              },\n              small: {\n                url: '/api/media/file/zZpFFeluQXVexiYXUJ6lu-600x400.jpg',\n                width: 600,\n                height: 400,\n                mimeType: 'image/jpeg',\n                filesize: 27963,\n                filename: 'zZpFFeluQXVexiYXUJ6lu-600x400.jpg'\n              },\n              medium: {\n                url: '/api/media/file/zZpFFeluQXVexiYXUJ6lu-900x600.jpg',\n                width: 900,\n                height: 600,\n                mimeType: 'image/jpeg',\n                filesize: 59628,\n                filename: 'zZpFFeluQXVexiYXUJ6lu-900x600.jpg'\n              },\n              large: {\n                url: '/api/media/file/zZpFFeluQXVexiYXUJ6lu-1400x933.jpg',\n                width: 1400,\n                height: 933,\n                mimeType: 'image/jpeg',\n                filesize: 121948,\n                filename: 'zZpFFeluQXVexiYXUJ6lu-1400x933.jpg'\n              },\n              xlarge: {\n                url: '/api/media/file/zZpFFeluQXVexiYXUJ6lu-1920x1280.jpg',\n                width: 1920,\n                height: 1280,\n                mimeType: 'image/jpeg',\n                filesize: 195431,\n                filename: 'zZpFFeluQXVexiYXUJ6lu-1920x1280.jpg'\n              }\n            }\n          },\n          description: 'See how FinOps enhances GenAI by optimising costs, boosting efficiency, and driving innovation with informed financial and operational strategies.'\n        },\n        publishedAt: '2025-02-18T16:04:50.489Z',\n        authors: [{\n          id: 16,\n          name: 'Derek Ho',\n          email: 'd.ho@reply.com',\n          jobRole: 'SC2',\n          manager: 2,\n          about: 'Senior AI & Cloud Consultant',\n          profilePicture: 12,\n          workHistory: [],\n          certifications: [],\n          areasOfExpertise: [],\n          dateOfBirth: '2020-10-15T12:00:00.000Z',\n          joinDate: '2021-08-09T12:00:00.000Z',\n          linkedIn: 'www.linkedin.com/in/derekmhho',\n          role: 'user',\n          updatedAt: '2025-03-17T09:43:57.552Z',\n          createdAt: '2025-01-13T10:49:09.359Z',\n          enableAPIKey: null,\n          apiKey: null\n        }, {\n          id: 12,\n          name: 'Ben Num',\n          email: 'b.num@reply.com',\n          jobRole: 'C2',\n          manager: 3,\n          about: null,\n          profilePicture: 15,\n          workHistory: [],\n          certifications: [],\n          areasOfExpertise: [],\n          dateOfBirth: '2025-12-29T12:00:00.000Z',\n          joinDate: '2023-09-11T12:00:00.000Z',\n          linkedIn: null,\n          role: 'user',\n          updatedAt: '2025-02-12T15:25:13.837Z',\n          createdAt: '2025-01-10T14:07:25.875Z',\n          enableAPIKey: null,\n          apiKey: null\n        }],\n        populatedAuthors: [{\n          id: '16',\n          name: 'Derek Ho'\n        }, {\n          id: '12',\n          name: 'Ben Num'\n        }],\n        slug: 'finops-enhanced-genai-inform-optimise-operate-innovate',\n        slugLock: true,\n        updatedAt: '2025-04-01T10:03:00.931Z',\n        createdAt: '2025-03-31T20:28:04.118Z'\n      }\n    }\n  }\n}",...LotsOfFormatting.parameters?.docs?.source}}}},"./src/common-types.ts":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{__webpack_require__.d(__webpack_exports__,{R:()=>blurDataUrl});const blurDataUrl="data:image/jpeg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAALABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAYEBQf/xAAgEAABBAICAwEAAAAAAAAAAAABAAIDBBEhEjEFBhMi/8QAFgEBAQEAAAAAAAAAAAAAAAAABAMF/8QAHBEAAgICAwAAAAAAAAAAAAAAAQIAIQMEBRFR/9oADAMBAAIRAxEAPwBqrV3PcNFL3s1Blny9eX7uYa7mtLAN95yFp9StCHajCp/YIImeUi4xtHLGdd7V9wkoOvZncagXIS10ZENFzsEA7GUJybBHxb+B0EJIeBOG5//Z"},"./src/components/Heros/PostHero/index.tsx":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{__webpack_require__.d(__webpack_exports__,{H:()=>PostHero});var react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__=__webpack_require__("./node_modules/.pnpm/next@15.1.3_@babel+core@7.26.0_react-dom@19.0.0_react@19.0.0__react@19.0.0_sass@1.83.0/node_modules/next/dist/compiled/react/jsx-runtime.js"),react__WEBPACK_IMPORTED_MODULE_1__=__webpack_require__("./node_modules/.pnpm/next@15.1.3_@babel+core@7.26.0_react-dom@19.0.0_react@19.0.0__react@19.0.0_sass@1.83.0/node_modules/next/dist/compiled/react/index.js"),next_image__WEBPACK_IMPORTED_MODULE_2__=__webpack_require__("./node_modules/.pnpm/@storybook+nextjs@8.6.12_esbuild@0.24.2_next@15.1.3_@babel+core@7.26.0_react-dom@19.0.0_ae06836f3e3dbad077fc9fe3354a9d03/node_modules/@storybook/nextjs/dist/images/next-image.mjs"),_lib_utils_formatDateTime__WEBPACK_IMPORTED_MODULE_3__=__webpack_require__("./src/utils/formatDateTime.ts"),_components_ui__WEBPACK_IMPORTED_MODULE_4__=__webpack_require__("./src/components/ui/badge.tsx");const PostHero=({post})=>{var _meta_image;const{categories,meta,populatedAuthors,publishedAt,title}=post;return(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)("div",{className:"relative grid pt-24",children:[(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("div",{className:"relative z-10 flex flex-col justify-end min-h-[50vh] text-foreground dark:text-foreground pt-24 p-6 lg:p-12",children:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)("div",{className:"container mx-auto",children:[(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("h1",{className:"mb-6 text-[clamp(2rem,1.5rem+1.5vw,3.5rem)] font-bold leading-tight ",children:title}),(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)("div",{className:"flex flex-col gap-4 md:flex-row md:gap-16 ",children:[populatedAuthors&&populatedAuthors.length>0&&(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)("div",{className:"flex flex-col gap-1",children:[(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)("p",{className:"text-sm",children:["Author",populatedAuthors.length>1?"s":""]}),(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("p",{children:populatedAuthors.map(((author,index)=>(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)(react__WEBPACK_IMPORTED_MODULE_1__.Fragment,{children:[author.name,index<populatedAuthors.length-2&&", ",index===populatedAuthors.length-2&&(populatedAuthors.length>2?", and ":" and ")]},author.id)))})]}),publishedAt&&(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)("div",{className:"flex flex-col gap-1",children:[(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("p",{className:"text-sm",children:"Date Published"}),(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("time",{dateTime:publishedAt,children:(0,_lib_utils_formatDateTime__WEBPACK_IMPORTED_MODULE_3__.r6)(publishedAt)})]}),categories&&categories.length>0&&(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)("div",{className:"flex flex-col gap-1",children:[(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("p",{className:"text-sm font-medium",children:"Categories"}),(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("div",{className:"flex flex-wrap gap-2",children:categories.map(((category,index)=>"object"==typeof category&&null!==category&&(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(_components_ui__WEBPACK_IMPORTED_MODULE_4__.E,{className:"px-3 py-1 mx-1",children:category.title||"Untitled category"},category.id||index)))})]})]})]})}),(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)("div",{className:"absolute inset-0 w-full h-full",children:[(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(next_image__WEBPACK_IMPORTED_MODULE_2__.A,{className:"object-cover",alt:`Cover image for ${title}`,src:(null==meta||null===(_meta_image=meta.image)||void 0===_meta_image?void 0:_meta_image.url)||"/assets/images/blog/gradient.png",fill:!0,priority:!0,sizes:"100vw"}),(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("div",{className:"absolute pointer-events-none left-0 bottom-0 w-full h-1/2 bg-gradient-to-t from-background dark:from-black to-transparent"})]})]})};PostHero.__docgenInfo={description:"",methods:[],displayName:"PostHero",props:{post:{required:!0,tsType:{name:"Post"},description:""}}}},"./src/components/Menus/Categories.tsx":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{__webpack_require__.d(__webpack_exports__,{L:()=>Categories});var react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__=__webpack_require__("./node_modules/.pnpm/next@15.1.3_@babel+core@7.26.0_react-dom@19.0.0_react@19.0.0__react@19.0.0_sass@1.83.0/node_modules/next/dist/compiled/react/jsx-runtime.js"),_lib_utils_cn__WEBPACK_IMPORTED_MODULE_2__=__webpack_require__("./src/utils/cn.ts"),next_navigation__WEBPACK_IMPORTED_MODULE_1__=__webpack_require__("./node_modules/.pnpm/@storybook+nextjs@8.6.12_esbuild@0.24.2_next@15.1.3_@babel+core@7.26.0_react-dom@19.0.0_ae06836f3e3dbad077fc9fe3354a9d03/node_modules/@storybook/nextjs/dist/export-mocks/navigation/index.mjs"),_components_ui_card__WEBPACK_IMPORTED_MODULE_3__=__webpack_require__("./src/components/ui/card.tsx"),_barrel_optimize_names_ExternalLink_lucide_react__WEBPACK_IMPORTED_MODULE_4__=__webpack_require__("./node_modules/.pnpm/lucide-react@0.469.0_react@19.0.0/node_modules/lucide-react/dist/esm/icons/external-link.js");(0,_lib_utils_cn__WEBPACK_IMPORTED_MODULE_2__.cn)("transition-colors duration-400 hover:text-primary ease-in-out");function Categories({title,links}){const searchParams=(0,next_navigation__WEBPACK_IMPORTED_MODULE_1__.useSearchParams)(),pathname=(0,next_navigation__WEBPACK_IMPORTED_MODULE_1__.usePathname)(),{replace}=(0,next_navigation__WEBPACK_IMPORTED_MODULE_1__.useRouter)();return(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)(_components_ui_card__WEBPACK_IMPORTED_MODULE_3__.Zp,{children:[(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(_components_ui_card__WEBPACK_IMPORTED_MODULE_3__.aR,{children:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(_components_ui_card__WEBPACK_IMPORTED_MODULE_3__.ZB,{className:"text-accent",children:title&&title})}),(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(_components_ui_card__WEBPACK_IMPORTED_MODULE_3__.Wu,{children:links&&links.length>0&&(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("nav",{"aria-label":"footer links navigation",children:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("ul",{className:"grid gap-2.5 ",children:links.map(((link,index)=>(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)("li",{className:"flex items-center text-sm text-primary hover:text-accent dark:text-foreground first:pt-0 hover:cursor-pointer",onClick:e=>{e.preventDefault(),function handleCategory(value){const params=new URLSearchParams(searchParams);value?params.set("category",value):params.delete("category"),replace(`${pathname}?${params.toString()}`)}(link.href)},children:[link.label,(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(_barrel_optimize_names_ExternalLink_lucide_react__WEBPACK_IMPORTED_MODULE_4__.A,{className:"ml-1 h-3 w-3"})]},index)))})})})]})}Categories.__docgenInfo={description:"",methods:[],displayName:"Categories",props:{title:{required:!1,tsType:{name:"string"},description:""},links:{required:!0,tsType:{name:"Array",elements:[{name:"LinkProps"}],raw:"LinkProps[]"},description:""}}}},"./src/components/Other/Container.tsx":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{__webpack_require__.d(__webpack_exports__,{m:()=>Container});var react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__=__webpack_require__("./node_modules/.pnpm/next@15.1.3_@babel+core@7.26.0_react-dom@19.0.0_react@19.0.0__react@19.0.0_sass@1.83.0/node_modules/next/dist/compiled/react/jsx-runtime.js"),_lib_utils__WEBPACK_IMPORTED_MODULE_1__=__webpack_require__("./src/utils/cn.ts");function Container({children,isFluid=!1,isNoPadding=!1,className=""}){const containerClasses=(0,_lib_utils__WEBPACK_IMPORTED_MODULE_1__.cn)("container",isFluid&&"full-width",isNoPadding&&"no-padding",className);return(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("div",{className:containerClasses,children})}Container.__docgenInfo={description:"Container provide content containment, padding, and alignment within specific devices or viewports.",methods:[],displayName:"Container",props:{children:{required:!0,tsType:{name:"ReactReactNode",raw:"React.ReactNode"},description:"The content or components to be rendered inside the container.\n@type {React.ReactNode}"},isFluid:{required:!1,tsType:{name:"boolean"},description:"Determines if the container should have a full width.\n@type {boolean}",defaultValue:{value:"false",computed:!1}},isNoPadding:{required:!1,tsType:{name:"boolean"},description:"Determines if the container should have no padding.\n@type {boolean}",defaultValue:{value:"false",computed:!1}},className:{required:!1,tsType:{name:"string"},description:"Additional class names to apply to the container.\n@type {string}",defaultValue:{value:"''",computed:!1}}}}},"./src/components/ui/badge.tsx":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{__webpack_require__.d(__webpack_exports__,{E:()=>Badge});var react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__=__webpack_require__("./node_modules/.pnpm/next@15.1.3_@babel+core@7.26.0_react-dom@19.0.0_react@19.0.0__react@19.0.0_sass@1.83.0/node_modules/next/dist/compiled/react/jsx-runtime.js"),class_variance_authority__WEBPACK_IMPORTED_MODULE_2__=(__webpack_require__("./node_modules/.pnpm/next@15.1.3_@babel+core@7.26.0_react-dom@19.0.0_react@19.0.0__react@19.0.0_sass@1.83.0/node_modules/next/dist/compiled/react/index.js"),__webpack_require__("./node_modules/.pnpm/class-variance-authority@0.7.1/node_modules/class-variance-authority/dist/index.mjs")),_lib_utils__WEBPACK_IMPORTED_MODULE_3__=__webpack_require__("./src/utils/cn.ts");const badgeVariants=(0,class_variance_authority__WEBPACK_IMPORTED_MODULE_2__.F)("inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2",{variants:{variant:{default:"border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80",secondary:"border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80",destructive:"border-transparent bg-destructive text-destructive-foreground shadow hover:bg-destructive/80",outline:"text-foreground"}},defaultVariants:{variant:"default"}});function Badge({className,variant,...props}){return(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("div",{className:(0,_lib_utils__WEBPACK_IMPORTED_MODULE_3__.cn)(badgeVariants({variant}),className),...props})}Badge.__docgenInfo={description:"",methods:[],displayName:"Badge",composes:["VariantProps"]}},"./src/components/ui/card.tsx":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{__webpack_require__.d(__webpack_exports__,{BT:()=>CardDescription,Wu:()=>CardContent,ZB:()=>CardTitle,Zp:()=>Card,aR:()=>CardHeader,wL:()=>CardFooter});var react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__=__webpack_require__("./node_modules/.pnpm/next@15.1.3_@babel+core@7.26.0_react-dom@19.0.0_react@19.0.0__react@19.0.0_sass@1.83.0/node_modules/next/dist/compiled/react/jsx-runtime.js"),react__WEBPACK_IMPORTED_MODULE_1__=__webpack_require__("./node_modules/.pnpm/next@15.1.3_@babel+core@7.26.0_react-dom@19.0.0_react@19.0.0__react@19.0.0_sass@1.83.0/node_modules/next/dist/compiled/react/index.js"),_lib_utils__WEBPACK_IMPORTED_MODULE_2__=__webpack_require__("./src/utils/cn.ts");const Card=react__WEBPACK_IMPORTED_MODULE_1__.forwardRef((({className,...props},ref)=>(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("div",{ref,className:(0,_lib_utils__WEBPACK_IMPORTED_MODULE_2__.cn)("rounded-xl border bg-card text-card-foreground shadow",className),...props})));Card.displayName="Card";const CardHeader=react__WEBPACK_IMPORTED_MODULE_1__.forwardRef((({className,...props},ref)=>(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("div",{ref,className:(0,_lib_utils__WEBPACK_IMPORTED_MODULE_2__.cn)("flex flex-col space-y-1.5 p-6",className),...props})));CardHeader.displayName="CardHeader";const CardTitle=react__WEBPACK_IMPORTED_MODULE_1__.forwardRef((({className,...props},ref)=>(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("div",{ref,className:(0,_lib_utils__WEBPACK_IMPORTED_MODULE_2__.cn)("font-semibold leading-none tracking-tight",className),...props})));CardTitle.displayName="CardTitle";const CardDescription=react__WEBPACK_IMPORTED_MODULE_1__.forwardRef((({className,...props},ref)=>(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("div",{ref,className:(0,_lib_utils__WEBPACK_IMPORTED_MODULE_2__.cn)("text-sm text-muted-foreground",className),...props})));CardDescription.displayName="CardDescription";const CardContent=react__WEBPACK_IMPORTED_MODULE_1__.forwardRef((({className,...props},ref)=>(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("div",{ref,className:(0,_lib_utils__WEBPACK_IMPORTED_MODULE_2__.cn)("p-6 pt-0",className),...props})));CardContent.displayName="CardContent";const CardFooter=react__WEBPACK_IMPORTED_MODULE_1__.forwardRef((({className,...props},ref)=>(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("div",{ref,className:(0,_lib_utils__WEBPACK_IMPORTED_MODULE_2__.cn)("flex items-center p-6 pt-0",className),...props})));CardFooter.displayName="CardFooter",Card.__docgenInfo={description:"",methods:[],displayName:"Card"},CardHeader.__docgenInfo={description:"",methods:[],displayName:"CardHeader"},CardFooter.__docgenInfo={description:"",methods:[],displayName:"CardFooter"},CardTitle.__docgenInfo={description:"",methods:[],displayName:"CardTitle"},CardDescription.__docgenInfo={description:"",methods:[],displayName:"CardDescription"},CardContent.__docgenInfo={description:"",methods:[],displayName:"CardContent"}},"./src/sections/BlogDetail.tsx":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{__webpack_require__.d(__webpack_exports__,{s:()=>BlogDetail});var react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__=__webpack_require__("./node_modules/.pnpm/next@15.1.3_@babel+core@7.26.0_react-dom@19.0.0_react@19.0.0__react@19.0.0_sass@1.83.0/node_modules/next/dist/compiled/react/jsx-runtime.js"),_common_types__WEBPACK_IMPORTED_MODULE_5__=__webpack_require__("./src/common-types.ts"),_components_Other_Container__WEBPACK_IMPORTED_MODULE_8__=__webpack_require__("./src/components/Other/Container.tsx"),_components_Other_CustomLink__WEBPACK_IMPORTED_MODULE_6__=__webpack_require__("./src/components/Other/CustomLink.tsx"),next_image__WEBPACK_IMPORTED_MODULE_1__=__webpack_require__("./node_modules/.pnpm/@storybook+nextjs@8.6.12_esbuild@0.24.2_next@15.1.3_@babel+core@7.26.0_react-dom@19.0.0_ae06836f3e3dbad077fc9fe3354a9d03/node_modules/@storybook/nextjs/dist/images/next-image.mjs"),_components_Payload_RichText__WEBPACK_IMPORTED_MODULE_9__=__webpack_require__("./src/components/Payload/RichText/index.tsx"),next_navigation__WEBPACK_IMPORTED_MODULE_2__=__webpack_require__("./node_modules/.pnpm/@storybook+nextjs@8.6.12_esbuild@0.24.2_next@15.1.3_@babel+core@7.26.0_react-dom@19.0.0_ae06836f3e3dbad077fc9fe3354a9d03/node_modules/@storybook/nextjs/dist/export-mocks/navigation/index.mjs"),_components_Menus_Categories__WEBPACK_IMPORTED_MODULE_11__=__webpack_require__("./src/components/Menus/Categories.tsx"),_components_ui_card__WEBPACK_IMPORTED_MODULE_4__=__webpack_require__("./src/components/ui/card.tsx"),_components_ui_button__WEBPACK_IMPORTED_MODULE_10__=__webpack_require__("./src/components/ui/button.tsx"),next_link__WEBPACK_IMPORTED_MODULE_3__=__webpack_require__("./node_modules/.pnpm/next@15.1.3_@babel+core@7.26.0_react-dom@19.0.0_react@19.0.0__react@19.0.0_sass@1.83.0/node_modules/next/link.js"),next_link__WEBPACK_IMPORTED_MODULE_3___default=__webpack_require__.n(next_link__WEBPACK_IMPORTED_MODULE_3__),_barrel_optimize_names_FaLinkedin_react_icons_fa6__WEBPACK_IMPORTED_MODULE_7__=__webpack_require__("__barrel_optimize__?names=FaInstagram,FaLinkedin!=!./node_modules/.pnpm/react-icons@5.4.0_react@19.0.0/node_modules/react-icons/fa6/index.mjs"),console=__webpack_require__("./node_modules/.pnpm/console-browserify@1.2.0/node_modules/console-browserify/index.js");function Author({image,name,about,socialLinks}){return!image||!image.src||image.src.length<3||!name?null:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("div",{className:"mt-1 z-10 px-0 pt-0 lg:px-10",children:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(_components_ui_card__WEBPACK_IMPORTED_MODULE_4__.Zp,{children:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)(_components_ui_card__WEBPACK_IMPORTED_MODULE_4__.Wu,{className:"flex flex-col items-center",children:[image&&image.src&&(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(next_image__WEBPACK_IMPORTED_MODULE_1__.A,{src:image.src,alt:image.alt||"",width:127,height:127,placeholder:"blur",blurDataURL:_common_types__WEBPACK_IMPORTED_MODULE_5__.R,className:"mx-auto mt-6 rounded-full object-cover"}),(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)("h3",{className:"flex items-center ali font-secondary text-center py-2 text-lg leading-[1.25] text-accent md:text-xl",children:[name,socialLinks&&socialLinks.length>0&&(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("nav",{"aria-label":"social links",children:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("ul",{className:"inline-flex items-center divide-x  divide-accent/50 text-accent dark:divide-accent/50  dark:text-white",children:socialLinks.map(((socialLink,index)=>socialLink.href&&(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("li",{children:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(_components_Other_CustomLink__WEBPACK_IMPORTED_MODULE_6__.A,{href:socialLink.href,openNewTab:!0,className:"block px-4 text-base/[1.75] transition-transform duration-350 hover:-translate-y-1 hover:text-accents",children:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("span",{children:socialLink.icon})})},index)))})})]}),(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("p",{children:about})]})})})}function BlogDetail({page,categoryList,edit=!1,path="/admin/collections/posts/"}){var _populatedAuthors_;if(!page)return(0,next_navigation__WEBPACK_IMPORTED_MODULE_2__.notFound)();const{meta,populatedAuthors,authors,categories,content,title}=page,authorMap=(meta&&meta.image&&meta.image.url,meta&&meta.image&&meta.image.alt,null==populatedAuthors||null===(_populatedAuthors_=populatedAuthors[0])||void 0===_populatedAuthors_||_populatedAuthors_.name,null==meta||meta.description,null==authors?void 0:authors.map((author=>{var _author_profilePicture_sizes_square,_author_profilePicture_sizes,_author_profilePicture_sizes_thumbnail,_author_profilePicture_sizes1;const val=author.profilePicture&&(null===(_author_profilePicture_sizes=author.profilePicture.sizes)||void 0===_author_profilePicture_sizes||null===(_author_profilePicture_sizes_square=_author_profilePicture_sizes.square)||void 0===_author_profilePicture_sizes_square?void 0:_author_profilePicture_sizes_square.url)||author.profilePicture&&(null===(_author_profilePicture_sizes1=author.profilePicture.sizes)||void 0===_author_profilePicture_sizes1||null===(_author_profilePicture_sizes_thumbnail=_author_profilePicture_sizes1.thumbnail)||void 0===_author_profilePicture_sizes_thumbnail?void 0:_author_profilePicture_sizes_thumbnail.url)||"";var _author_linkedIn;return console.log("val:",val),{name:author.name||"",about:author.about||"",image:{src:val,alt:author.name||"blog author"},socialLinks:[{icon:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(_barrel_optimize_names_FaLinkedin_react_icons_fa6__WEBPACK_IMPORTED_MODULE_7__.QEs,{}),href:null!==(_author_linkedIn=author.linkedIn)&&void 0!==_author_linkedIn?_author_linkedIn:""}]}})));return console.log(authorMap),(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(_components_Other_Container__WEBPACK_IMPORTED_MODULE_8__.m,{children:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)("div",{className:"grid gap-30px lg:grid-cols-[1fr_410px]",children:[(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("div",{children:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)("div",{className:"[&_p+P]:mt-4",children:[(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("div",{className:"my-4 h-px bg-body/30 lg:my-5"}),(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(_components_Payload_RichText__WEBPACK_IMPORTED_MODULE_9__.s,{content,enableGutter:!1,className:"prose-invert"})]})}),(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)("div",{className:"grid gap-30px self-baseline max-md:mx-auto max-md:max-w-[410px] lg:gap-10",children:[edit&&(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("div",{className:"mt-4 lg:-mt-10 z-10 px-0 pt-0 lg:px-10",children:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)(_components_ui_card__WEBPACK_IMPORTED_MODULE_4__.Zp,{children:[(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(_components_ui_card__WEBPACK_IMPORTED_MODULE_4__.aR,{children:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(_components_ui_card__WEBPACK_IMPORTED_MODULE_4__.ZB,{className:"text-accent",children:"Content Actions"})}),(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)(_components_ui_card__WEBPACK_IMPORTED_MODULE_4__.Wu,{children:[(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("p",{className:"mb-4 text-sm text-muted-foreground",children:"Edit this page in the CMS"}),(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(next_link__WEBPACK_IMPORTED_MODULE_3___default(),{href:`${path}${page.id}`,children:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(_components_ui_button__WEBPACK_IMPORTED_MODULE_10__.$,{variant:"outline",className:"w-full text-accent hover:text-foreground",children:"Edit"})})]})]})}),authorMap&&authorMap.map(((author,index)=>(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(Author,{...author},index))),categoryList&&categoryList.links&&(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("div",{className:"mt-4 px-0 pt-0 lg:px-10",children:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(_components_Menus_Categories__WEBPACK_IMPORTED_MODULE_11__.L,{links:categoryList.links,title:categoryList.title})})]})]})})}BlogDetail.__docgenInfo={description:"",methods:[],displayName:"BlogDetail",props:{page:{required:!0,tsType:{name:"PayloadPost"},description:""},categoryList:{required:!1,tsType:{name:"CategoryListProps"},description:""},edit:{required:!1,tsType:{name:"boolean"},description:"",defaultValue:{value:"false",computed:!1}},path:{required:!1,tsType:{name:"string"},description:"",defaultValue:{value:"'/admin/collections/posts/'",computed:!1}}}}},"./src/utils/formatDateTime.ts":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{__webpack_require__.d(__webpack_exports__,{oj:()=>formatDateTimeStringShort,r6:()=>formatDateTime});const formatDateTime=timestamp=>{let date=new Date;timestamp&&(date=new Date(timestamp));const months=date.getMonth(),days=date.getDate();return`${days<10?`0${days}`:days}/${months+1<10?`0${months+1}`:months+1}/${date.getFullYear()}`},formatDateTimeStringShort=timestamp=>{const date=timestamp?new Date(timestamp):new Date,dayOfWeek=new Intl.DateTimeFormat("en-US",{weekday:"long"}).format(date),day=date.getDate(),month=new Intl.DateTimeFormat("en-US",{month:"short"}).format(date);return`${dayOfWeek} ${day}${(day=>{if(day>3&&day<21)return"th";switch(day%10){case 1:return"st";case 2:return"nd";case 3:return"rd";default:return"th"}})(day)} ${month}`}},"./node_modules/.pnpm/lucide-react@0.469.0_react@19.0.0/node_modules/lucide-react/dist/esm/icons/external-link.js":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{__webpack_require__.d(__webpack_exports__,{A:()=>ExternalLink});const ExternalLink=(0,__webpack_require__("./node_modules/.pnpm/lucide-react@0.469.0_react@19.0.0/node_modules/lucide-react/dist/esm/createLucideIcon.js").A)("ExternalLink",[["path",{d:"M15 3h6v6",key:"1q9fwt"}],["path",{d:"M10 14 21 3",key:"gplh6r"}],["path",{d:"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6",key:"a6xqqp"}]])},"./node_modules/.pnpm/lucide-react@0.469.0_react@19.0.0/node_modules/lucide-react/dist/esm/icons/moon.js":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{__webpack_require__.d(__webpack_exports__,{A:()=>Moon});const Moon=(0,__webpack_require__("./node_modules/.pnpm/lucide-react@0.469.0_react@19.0.0/node_modules/lucide-react/dist/esm/createLucideIcon.js").A)("Moon",[["path",{d:"M12 3a6 6 0 0 0 9 9 9 9 0 1 1-9-9Z",key:"a7tn18"}]])},"./node_modules/.pnpm/lucide-react@0.469.0_react@19.0.0/node_modules/lucide-react/dist/esm/icons/sun.js":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{__webpack_require__.d(__webpack_exports__,{A:()=>Sun});const Sun=(0,__webpack_require__("./node_modules/.pnpm/lucide-react@0.469.0_react@19.0.0/node_modules/lucide-react/dist/esm/createLucideIcon.js").A)("Sun",[["circle",{cx:"12",cy:"12",r:"4",key:"4exip2"}],["path",{d:"M12 2v2",key:"tus03m"}],["path",{d:"M12 20v2",key:"1lh1kg"}],["path",{d:"m4.93 4.93 1.41 1.41",key:"149t6j"}],["path",{d:"m17.66 17.66 1.41 1.41",key:"ptbguv"}],["path",{d:"M2 12h2",key:"1t8f8n"}],["path",{d:"M20 12h2",key:"1q8mjw"}],["path",{d:"m6.34 17.66-1.41 1.41",key:"1m8zz5"}],["path",{d:"m19.07 4.93-1.41 1.41",key:"1shlcs"}]])},"./node_modules/.pnpm/next-themes@0.4.4_react-dom@19.0.0_react@19.0.0__react@19.0.0/node_modules/next-themes/dist/index.mjs":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{__webpack_require__.d(__webpack_exports__,{D:()=>z,N:()=>J});var react__WEBPACK_IMPORTED_MODULE_0__=__webpack_require__("./node_modules/.pnpm/next@15.1.3_@babel+core@7.26.0_react-dom@19.0.0_react@19.0.0__react@19.0.0_sass@1.83.0/node_modules/next/dist/compiled/react/index.js"),L=(e,r,s,u,d,m,l,h)=>{let c=document.documentElement,v=["light","dark"];function p(i){(Array.isArray(e)?e:[e]).forEach((y=>{let k="class"===y,S=k&&m?d.map((f=>m[f]||f)):d;k?(c.classList.remove(...S),c.classList.add(i)):c.setAttribute(y,i)})),function R(i){h&&v.includes(i)&&(c.style.colorScheme=i)}(i)}if(u)p(u);else try{let i=localStorage.getItem(r)||s;p(l&&"system"===i?function a(){return window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"}():i)}catch(i){}},M=["light","dark"],Q="(prefers-color-scheme: dark)",U="undefined"==typeof window,E=react__WEBPACK_IMPORTED_MODULE_0__.createContext(void 0),N={setTheme:e=>{},themes:[]},z=()=>{var e;return null!=(e=react__WEBPACK_IMPORTED_MODULE_0__.useContext(E))?e:N},J=e=>react__WEBPACK_IMPORTED_MODULE_0__.useContext(E)?react__WEBPACK_IMPORTED_MODULE_0__.createElement(react__WEBPACK_IMPORTED_MODULE_0__.Fragment,null,e.children):react__WEBPACK_IMPORTED_MODULE_0__.createElement(_,{...e}),V=["light","dark"],_=({forcedTheme:e,disableTransitionOnChange:r=!1,enableSystem:s=!0,enableColorScheme:u=!0,storageKey:d="theme",themes:m=V,defaultTheme:l=(s?"system":"light"),attribute:h="data-theme",value:c,children:v,nonce:p,scriptProps:R})=>{let[a,i]=react__WEBPACK_IMPORTED_MODULE_0__.useState((()=>b(d,l))),[w,y]=react__WEBPACK_IMPORTED_MODULE_0__.useState((()=>b(d))),k=c?Object.values(c):m,S=react__WEBPACK_IMPORTED_MODULE_0__.useCallback((n=>{let o=n;if(!o)return;"system"===n&&s&&(o=I());let T=c?c[o]:o,C=r?W(p):null,P=document.documentElement,x=g=>{"class"===g?(P.classList.remove(...k),T&&P.classList.add(T)):g.startsWith("data-")&&(T?P.setAttribute(g,T):P.removeAttribute(g))};if(Array.isArray(h)?h.forEach(x):x(h),u){let g=M.includes(l)?l:null,O=M.includes(o)?o:g;P.style.colorScheme=O}null==C||C()}),[p]),f=react__WEBPACK_IMPORTED_MODULE_0__.useCallback((n=>{let o="function"==typeof n?n(a):n;i(o);try{localStorage.setItem(d,o)}catch(T){}}),[a]),A=react__WEBPACK_IMPORTED_MODULE_0__.useCallback((n=>{let o=I(n);y(o),"system"===a&&s&&!e&&S("system")}),[a,e]);react__WEBPACK_IMPORTED_MODULE_0__.useEffect((()=>{let n=window.matchMedia(Q);return n.addListener(A),A(n),()=>n.removeListener(A)}),[A]),react__WEBPACK_IMPORTED_MODULE_0__.useEffect((()=>{let n=o=>{o.key===d&&(o.newValue?i(o.newValue):f(l))};return window.addEventListener("storage",n),()=>window.removeEventListener("storage",n)}),[f]),react__WEBPACK_IMPORTED_MODULE_0__.useEffect((()=>{S(null!=e?e:a)}),[e,a]);let D=react__WEBPACK_IMPORTED_MODULE_0__.useMemo((()=>({theme:a,setTheme:f,forcedTheme:e,resolvedTheme:"system"===a?w:a,themes:s?[...m,"system"]:m,systemTheme:s?w:void 0})),[a,f,e,w,s,m]);return react__WEBPACK_IMPORTED_MODULE_0__.createElement(E.Provider,{value:D},react__WEBPACK_IMPORTED_MODULE_0__.createElement(H,{forcedTheme:e,storageKey:d,attribute:h,enableSystem:s,enableColorScheme:u,defaultTheme:l,value:c,themes:m,nonce:p,scriptProps:R}),v)},H=react__WEBPACK_IMPORTED_MODULE_0__.memo((({forcedTheme:e,storageKey:r,attribute:s,enableSystem:u,enableColorScheme:d,defaultTheme:m,value:l,themes:h,nonce:c,scriptProps:v})=>{let p=JSON.stringify([s,r,m,e,h,l,u,d]).slice(1,-1);return react__WEBPACK_IMPORTED_MODULE_0__.createElement("script",{...v,suppressHydrationWarning:!0,nonce:"undefined"==typeof window?c:"",dangerouslySetInnerHTML:{__html:`(${L.toString()})(${p})`}})})),b=(e,r)=>{if(U)return;let s;try{s=localStorage.getItem(e)||void 0}catch(u){}return s||r},W=e=>{let r=document.createElement("style");return e&&r.setAttribute("nonce",e),r.appendChild(document.createTextNode("*,*::before,*::after{-webkit-transition:none!important;-moz-transition:none!important;-o-transition:none!important;-ms-transition:none!important;transition:none!important}")),document.head.appendChild(r),()=>{window.getComputedStyle(document.body),setTimeout((()=>{document.head.removeChild(r)}),1)}},I=e=>(e||(e=window.matchMedia(Q)),e.matches?"dark":"light")}}]);